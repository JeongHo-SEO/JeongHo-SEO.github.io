---
title: "[SIGIR 2021] Causal Intervention for Leveraging Popularity Bias in Recommendation"
date: "2025-07-24"
description: "ì¸ê³¼ ê°œì…(causal intervention)ì„ í†µí•´ í•´ë¡œìš´ ì˜í–¥ë§Œ ì œê±°í•˜ê³  ìœ ìµí•œ í¸í–¥ì€ í™œìš©"
toc: true
number-sections: true
---
- References
    - **Paper**: [Causal Intervention for Leveraging Popularity Bias in Recommendation](https://dl.acm.org/doi/abs/10.1145/3404835.3462875)
    - **Official Code**: [GitHub Repository](URL)
    - **Conference**: [SIGIR 2021](URL)

- [Presentation Slides](Presentation-Slides/SIGIR21-Causal_Intervention_for_Leveraging_Popularity_Bias_in_Recommendation.pdf)

# Proposal

### RS: Popularity Bias problem.

- Interaction frequencey [popularity] â†’ User-Item interaction data: long-tailed distribution.
    - Few head itemsê°€  most of the interactions ì°¨ì§€.
- Previous works â†’ Eliminate the effect of popularity bias
    1. Inverse Propensity Scoring (IPS)
        1. Propensity estimation ì–´ë ¤ì›€.
        2. High model variance.
    2. Causal Embedding
        1. Bias-free uniform data ì‚¬ìš©. â†’ Discard item popularity â†’  Expose randomly items to users â†’ êµ¬í•˜ê¸° ì–´ë ¤ì›€.
        â†’ Small data â†’ learning: unstable.
    3. Ranking Adjustment
        1. Heuristically designed
        2. Lack of theoretical foundations

### Idea

- Higher popularity items
    - Better intrinsic quality
    - Representing current trends
    - â†’ popularity biasë¥¼ ëª¨ë‘ ì‚­ì œí•˜ëŠ” ê²ƒì€ ë³„ë¡œ ì¢‹ì§€ ëª»í•¨.
- ì–´ë–»ê²Œ Popularity Biasë¥¼ RS ì„±ëŠ¥ì„ ìœ„í•´ ì‚¬ìš©[leverage]í•  ìˆ˜ ìˆì„ê¹Œ?
    1. Training ë‹¨ê³„ì—ì„œ Popularity Biasì˜ Bad impactsë¥¼ ì œê±°
    2. Inference ë‹¨ê³„ì—ì„œ desired popularity biasë¥¼ ì‚½ì…. [top-K recommendations ìƒì„±.]

### Causal Graph illustration

![image.png](attachment:9f5217ed-9c0f-4488-9b26-1c678747a70f:image.png)

- **Cause â†’ Effect: Directed Acyclic Graph [DAG]**
- **U, I, Z â†’ C**
- **Z â†’ I â†’ C & Zâ†’ C**
    - **Z: confounder, confounding effectë¥¼ ê°€ì§.**
    - **Z â†’ I â†’ C: Bad effect of popularity bias [bad effect to learn real user interest.]**
    - **Z â†’ I ë¶€ë¶„ì„ ì œê±°í•´ì•¼ í•¨.**
    - **do-calculus ì—°ì‚° ì‚¬ìš©. [de-confounded training]**
        - $ğ‘‘ğ‘œ(ğ¼)$ **forces to remove the impact of** $ğ¼â€™s$ **parent nodes**

### Proposal

- New training & inference paradigm: **Popularity-bias Deconfounding and Adjusting (PDA)**
    1. Training ë‹¨ê³„ì—ì„œ confounding popularity bias ì œê±°
    2. Inference ë‹¨ê³„ì—ì„œ, **Causal Intervention** â†’ desired popularity bias â†’ recommendation score ì¡°ì •.

# Primary Knowledge

### Notation

1. U: user, I: item
2. Upper-case character: random variable. e.g. $U,I$
3. lower-case character: specific value. e.g. $u,i$
4. Calligraphic font: sample space. e.g. $\mathcal{U}=\{u_1,\ldots,u_{|\mathcal{U}|}\}, \mathcal{I}=\{i_1,\ldots,i_{|\mathcal{I}|}\}$
5. Probability dist.: $P\left(\cdot\right)$
6. $\mathcal{D}_t$: të²ˆì§¸ stageì˜ data â†’ $\mathcal{D}=\cup_{t=1}^T \mathcal{D}_t$: historical data
7. $D_i^t$: Number of observed interactions for item i in $\mathcal{D_t}$

$$
m_i^t=\frac{D_i^t}{\sum\limits_{j\in\mathcal{I}}D_j^t}:\text{local popularity of item i on the stage t} \quad (1)
$$

<aside>
ğŸ’¡

Popularity = Itemâ€™s frequency

</aside>

### Metrics

- **Drift of Popularity (DP)** between stage t and stage s **[ì‹œê°„ì´ íë¥¼ìˆ˜ë¡ popularityê°€ ë³€í™”.]**
    
    $$
    \text{DP}\left(t,s\right)=\text{JSD}\left(\left[m_1^t, \ldots, m_{\mathcal{I}}^t\right],\left[m_1^s, \ldots, m_{\mathcal{I}}^s\right]\right) \quad (2)
    $$
    
    - Jensen-Shannon **Divergence**(JSD): **dis-similarity between two stages**
    - **ì‘ì„ìˆ˜ë¡ ë¶„í¬ ìœ ì‚¬.**

![image.png](attachment:5b987fb4-e97d-4e69-b4c3-678cb8d10935:image.png)

- 3 real-world dataset: Kwai, Douban, Tencent
- (a): datasetì— ë”°ë¼ ì¶”ì„¸ê°€ ë‹¤ë¦„.
- (b) ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì ì°¨ popularityì˜ ë³€í™”ê°€ ëˆ„ì ë¨.

# Framework

## Deconfounded Training

<aside>
ğŸ’¡

$ğ‘‘ğ‘œ(ğ¼)$ forces to remove the impact of $ğ¼â€™s$ parent nodes

</aside>

![image.png](attachment:ba47193e-321d-4446-bff1-1f1a0c8b5de7:image.png)

### Traditional predictive model

- $P\left(C|U=u,I=i\right)$: (user, item)ì— ëŒ€í•˜ì—¬ interactioní•  í™•ë¥ . $P\left(c=1|u,i\right)=??$
- ë†’ì€ ìˆœì„œëŒ€ë¡œ top-K recommendation.

### Paperâ€™s predictive model

- $Z â†’ I$ë¥¼ ì—†ì• ì•¼ í•¨. $I$ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ê³ , $do(I)$ë¥¼ ì‚¬ìš©.

<aside>
ğŸ’¡

**Training: $P\left(C|U,do\left(I\right)\right)=P\left(C|do\left(U\right),do\left(I\right)\right)=P\left(C|do\left(U,I\right)\right) \rightarrow P\left(c=1|do\left(U=u,I=i\right)\right)=??$**

</aside>

- **Figure 1-(b) = G, Figure 1-(c) = Gâ€™ì´ë¼ í•˜ë©´,**

$$
P\left(C|do\left(U,I\right)\right)
=P_{G'}\left(C|U,I\right)
=\sum\limits_{z\in Z} P_{G'}\left(C,z|U,I\right)
=\sum\limits_{z\in Z} P_{G'}\left(C|U,I,z\right)P_{G'}\left(z|U,I\right)
\\=\sum\limits_{z\in Z} P_{G'}\left(C|U,I,z\right)P_{G'}\left(z\right)
=\sum\limits_{z\in Z} P\left(C|U,I,z\right)P\left(z\right) \quad (3)
$$

### Step 1. $P\left(c=1|u,i,z\right)$ estimation. for $\hat{P}\left(c=1|do\left(u,i\right)\right)$

- $\Theta\text{: parameters of }P\left(c=1|U=u,I=i,z\right)$
- **Pair-wise BPR objective function with $L_2$ regularization term.**
    
    $$
    \mathcal{L}_{\text{BPR}}=
    -\sum\limits_{\left(u,i,j\right)\in \mathcal{D}} \log\sigma\left(
    P_{\Theta}\left(c=1|u,i,m_i^t \right) - P_{\Theta}\left(c=1|u,j,m_j^t \right)
    \right)
    +\lambda\|\Theta\|^2 \quad (4')
    \\
    \arg\min_{\Theta}\mathcal{L}_{\text{BPR}}= \hat{\Theta}
    $$
    
    - $U=u, I=i, Z=m_i^t$
    - $j$: negative sample for $u$ â†’ interactionì´ ì—†ëŠ” item
    - $\mathcal{L}_{\text{BPR}} \downarrow \quad \Leftrightarrow \quad P_{\Theta}\left(c=1|u,i,m_i^t \right) > P_{\Theta}\left(c=1|u,j,m_j^t \right)$: interactionì´ ì¡´ì¬í•˜ëŠ” itemì˜ interaction í™•ë¥ ì´ ë” í¬ë‹¤. trivial.
- **$\left(U,I\right), Z$ ë¶„ë¦¬. â†’ ì¥ì ì€ ëª…í™•í•˜ë‚˜ ì •ë‹¹í™” í•˜ëŠ” ë…¼ê±°ê°€ ì—†ìŒ. ê°€ì •ìœ¼ë¡œ íŒë‹¨.**
    
    $$
    P_{\Theta}\left(c=1|u,i,m_i^t \right)
    = \text{ELU}'\left(f_{\Theta}\left(u,i\right)\right)\times\left(m_i^t\right)^{\gamma} \quad (5)
    $$
    
    1. $f$ë¥¼ ë³€í™”ì‹œì¼œ ê°€ë©° extendableí•œ model ìƒì„± ê°€ëŠ¥
    2. Inferenceì—ì„œ popularity biasë¥¼ ì¡°ì •í•˜ê¸° ìš©ì´. $\left(m_i^t\right)^{\gamma}$
        1. $\gamma$: hyper-parameter for tuning.
        2. $\gamma \uparrow \quad \Rightarrow \text{higher impact of bias}$
    - In this paper, $f:\text{Matrix Factorization}$
    - $\text{ELU}$: Exponential Linear Unit [activation function]
        
        $$
        \text{ELU}'\left(x\right)=
        \begin{cases} e^{-x}, & \text{if } x \le 0 \\ x+1, & \text{else} \end{cases}   \quad(6)
        $$
        

### Step 2. $\sum\limits_{z\in Z} P\left(c=1|u,i,z\right)P\left(z\right)$  estimation

$$
P\left(c=1|do\left(u,i\right)\right)
=\sum\limits_{z\in Z} P\left(c=1|u,i,z\right)P\left(z\right)
=\sum\limits_{z\in Z}
P_{\Theta}\left(c=1|u,i,m_i^t \right) P\left(z\right)
\\= \sum\limits_{z\in Z}
\text{ELU}'\left(f_{\Theta}\left(u,i\right)\right)\times\left(m_i^t\right)^{\gamma}P\left(z\right)
= 
\text{ELU}'\left(f_{\Theta}\left(u,i\right)\right)\times \sum\limits_{z\in Z} z^{\gamma}P\left(z\right)
\\=
\text{ELU}'\left(f_{\Theta}\left(u,i\right)\right)\times \mathbb{E} \left(Z^{\gamma}\right)
$$

### **Popularity-bias Deconfounding (PD)**

- **$\mathbb{E} \left(Z^{\gamma}\right)$: constant. â†’ Popularity term $Z$: ì˜í–¥ ì‚¬ë¼ì§. [Zâ†’I path ì‚¬ë¼ì§.] â†’ Biasì˜ negative effect ì œê±°.**
- Estimated parameters $\hat{\Theta} \rightarrow 
\text{ELU}'\left(f_{\hat{\Theta}}\left(u,i\right)\right)\times \mathbb{E} \left(Z^{\gamma}\right) \rightarrow \hat{P}\left(c=1|do\left(U=u,I=i\right)\right)$

<aside>
ğŸ’¡

**Training: (user, item) ë§Œìœ¼ë¡œ í•™ìŠµ. $\hat{\Theta} \rightarrow
\text{ELU}'\left(f_{\hat{\Theta}}\left(u,i\right)\right)\times \mathbb{E} \left(Z^{\gamma}\right) \rightarrow \hat{P}\left(c=1|do\left(U=u,I=i\right)\right)$**

</aside>

## Adjusting Popularity Bias in Inference

- **Popularity Biasì˜ better usage: promoting, i.e, $\exist$ target popularity bias $\tilde{z}$**
- ë”°ë¼ì„œ target $\tilde{z}$ [desired popularity]ë¥¼ inferenceì— ë°˜ì˜í•  ìˆ˜ ìˆë‹¤.
    
    $$
    P\left(c=1|do\left(U=u,I=i\right), do\left(Z=\tilde{z}\right)\right)
    =P_{\Theta}\left(c=1|u,i,\tilde{m_i}\right)\quad(7)
    $$
    
    - $\tilde{m_i}$: popularity value of $\tilde{z}$, modeling with the time-series forecasting method.

### **Popularity-bias Deconfounding and Adjusting (PDA)**

$$
\tilde{m_i}=m_i^T + \alpha\left(m_i^T-m_i^{T-1}\right)\quad (8)
$$

- $m_i^T$: popularity value of the last stage T
- $\alpha$: hyper-parameter, control the popularity drift

$$
\text{PDA}_{u,i}=
\text{ELU}'\left(f_{\Theta}\left(u,i\right)\right)\times \left(\tilde{m_i}\right)^{\tilde{\gamma}} \quad (9)
$$

- $\tilde{\gamma}$: hyper-parameter for the strength of popularity bias

<aside>
ğŸ’¡

**[Inference] $\text{PDA}_{u,i}$: recommendation score â†’ each userì— ëŒ€í•˜ì—¬ ìƒìœ„ Kê°œì˜ itemì„ recommendation.**

</aside>

![image.png](attachment:296bb6b8-ae3f-4811-b892-cdc42fd87ab8:image.png)

![image.png](attachment:36fe81dc-e137-4f20-b166-1833a0a4b670:image.png)

<aside>
ğŸ’¡

**Inference: (user, item), target popularity bias $\tilde{z}$ â†’ $\text{PDA}_{u,i}=
\text{ELU}'\left(f_{\Theta}\left(u,i\right)\right)\times \left(\tilde{m_i}\right)^{\tilde{\gamma}}$â†’ top-K recommendation.**

</aside>

## Comparison with Correlation $P\left(C|U,I\right)$

$$
P\left(C|do\left(U,I\right)\right)
=P_{G'}\left(C|U,I\right)
=\sum\limits_{z\in Z} P_{G'}\left(C,z|U,I\right)
=\sum\limits_{z\in Z} P_{G'}\left(C|U,I,z\right)P_{G'}\left(z|U,I\right)
\\=\sum\limits_{z\in Z} P_{G'}\left(C|U,I,z\right)P_{G'}\left(z\right)
=\sum\limits_{z\in Z} P\left(C|U,I,z\right)P\left(z\right) \quad (3)
$$

$$
P\left(C|U,I\right)
=P_{G}\left(C|U,I\right)
=\sum\limits_{z\in Z} P_{G}\left(C,z|U,I\right)
=\sum\limits_{z\in Z} P_{G}\left(C|U,I,z\right)P_{G}\left(z|U,I\right)
\\=\sum\limits_{z\in Z} P_{G}\left(C|U,I,z\right)P_{G}\left(z|I\right)
=\sum\limits_{z\in Z} P\left(C|U,I,z\right)P\left(I|z\right)\frac{P\left(z\right)}{P\left(I\right)}
\propto \sum\limits_{z\in Z} P\left(C|U,I,z\right)P\left(I|z\right)P\left(z\right) \quad (10)
$$

- $P\left(I|z\right)=P\left(I=i|Z=m_i^t\right)$ â†’ Popularity Zê°€ trainingì— ì‚¬ìš©ë¨.
- **$P\left(C|U,I\right)$: correlation-based training**
- **$P\left(C|do\left(U,I\right)\right)$: causality-based training with causal intervention $do\left(\cdot\right)$**

# Experiments

<aside>
ğŸ’¡

- **RQ1:**
    1. **Does PD** achieve the goal of **removing the bad effect of popularity bias**?
    2. How is its **performance** compared with existing methods?
- **RQ2:**
    1. **Can PDA** effectively **inject desired popularity bias**?
    2. To what extent **leveraging popularity bias enhance** the recommendation **performance**.
</aside>

## Datasets

1. Kwai: clicking data
2. Douban Movie: user ratings for movies
3. Tencent: user interactions are â€œlikesâ€, which are reflective of user satisfaction but far more sparse than clicks.

## Baselines vs PD

![image.png](attachment:07500f26-f632-457f-88ce-a04379adec1a:image.png)

### Metrics

### ğŸ“Œ 1. Recall@k

- ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìƒí˜¸ì‘ìš©í•œ ì•„ì´í…œ ì¤‘ì—ì„œ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ëœ ë¹„ìœ¨
    
    $$
    â
    $$
    
- $\text{Relevant}_u$: ì‚¬ìš©ì $u$ê°€ ì‹¤ì œë¡œ ìƒí˜¸ì‘ìš©í•œ ì•„ì´í…œ ì§‘í•©
- $\text{Recommended}_u^k$: ëª¨ë¸ì´ ì‚¬ìš©ì $u$ì—ê²Œ ì¶”ì²œí•œ ìƒìœ„ $k$ê°œ ì•„ì´í…œ

---

### ğŸ“Œ 2. Precision@k

- ì¶”ì²œëœ ì•„ì´í…œ ì¤‘ì—ì„œ ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì¢‹ì•„í•œ(relevant) ì•„ì´í…œì˜ ë¹„ìœ¨
    
    $$
    
    \text{Precision@}k = \frac{|\text{Relevant}_u \cap \text{Recommended}_u^k|}{k}
    
    $$
    

---

### ğŸ“Œ 3. Hit Ratio (HR@k)

- ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ì— ì‚¬ìš©ìê°€ ì¢‹ì•„í•œ ì•„ì´í…œì´ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
    
    $$
    \text{HR@}k =
    \begin{cases}
    1 & \text{if } \text{Relevant}_u \cap \text{Recommended}_u^k \neq \emptyset \\\\
    0 & \text{otherwise}
    \end{cases}
    $$
    
- ì „ì²´ ì‚¬ìš©ì í‰ê· :
    
    $$
    \text{HR@}k = \frac{1}{|U|} \sum_{u \in U} \mathbb{I}\left[\text{Relevant}_u \cap \text{Recommended}_u^k \neq \emptyset\right]
    $$
    

---

### ğŸ“Œ 4. NDCG@k (Normalized Discounted Cumulative Gain)

- ì¶”ì²œëœ ì•„ì´í…œì˜ ìˆœì„œê°€ ì¤‘ìš”í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ìˆœìœ„ê¸°ë°˜ ì§€í‘œ
- **DCG (Discounted Cumulative Gain)**:
    
    $$
    \text{DCG@}k = \sum_{i=1}^{k} \frac{rel_i}{\log_2(i+1)}
    $$
    
    - $\text{rel}_i$: ì¶”ì²œëœ $i$ë²ˆì§¸ ì•„ì´í…œì´ relevantí•˜ë©´ 1, ì•„ë‹ˆë©´ 0
- **IDCG (Ideal DCG)**: relevance ìˆœìœ¼ë¡œ ì •ë ¬ëœ ìµœì  DCG
    
    $$
    \text{NDCG@}k = \frac{\text{DCG@}k}{\text{IDCG@}k} \in [0,1]
    $$
    

---

### ğŸ“Œ 5. Relative Improvement

- ê¸°ì¤€ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒë¥ 
    
    $$
    \text{Relative Improvement (\%)} = \frac{\text{New} - \text{Baseline}}{\text{Baseline}} \times 100
    $$
    
- **ì˜ˆì‹œ**:
    - ê¸°ì¡´ ëª¨ë¸ Recall@10 = 0.10
    - ìƒˆë¡œìš´ ëª¨ë¸ Recall@10 = 0.12
        
        â†’ Relative Improvement = 20%
        

---

### âœ… ì •ë¦¬ í‘œ

| Metric | ì„¤ëª… | ìˆ˜ì‹ ìš”ì•½ |
| --- | --- | --- |
| Recall@k | Relevant ì¤‘ ì–¼ë§ˆë‚˜ ë§ì·„ëŠ”ê°€ | $\frac{\text{TP}}{\text{TP + FN}}$ |
| Precision@k | ì¶”ì²œ ì¤‘ ì–¼ë§ˆë‚˜ Relevantí•œê°€ | $\frac{\text{TP}}{k}$ |
| Hit Ratio@k | í•˜ë‚˜ë¼ë„ ë§ì·„ëŠ”ê°€ | 0 or 1 |
| NDCG@k | ìˆœì„œê¹Œì§€ ê³ ë ¤í•œ ì •ë‹µì„± ì¸¡ì • | $\frac{DCG@k}{IDCG@k}$ |
| Relative Improv. | ê¸°ì¤€ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒë¥  | $\frac{\text{New} - \text{Baseline}}{\text{Baseline}}$ |

## Deconfounding Performance (RQ1)

### Baselines vs PD

- Group 1-10: average popularity
- Group 1: ê°€ì¥ ì¸ê¸° ë§ìŒ ~ Group 10: ê°€ì¥ ì¸ê¸° ì—†ìŒ.

![image.png](attachment:6e80a2a8-8aae-4d28-9859-827aad139414:image.png)

![image.png](attachment:b5f3bd4b-ae1a-470e-b703-8ebb67be4a74:image.png)

- **BPRMF**: Group 1ì— ë§ì€ ì¶”ì²œ â†’ popularityì™€ ì¶”ì²œì´ ë¹„ë¡€ â†’ popularity bias amplification.
- **DICE**: Group 5ì— ë§ì€ ì¶”ì²œ â†’ ë°˜ë°˜.
- **PD**: training ë°ì´í„°ì˜ RR ë¶„í¬ì™€ ê°€ì¥ ìœ ì‚¬ & í‘œì¤€í¸ì°¨(std. dev.)ê°€ ê°€ì¥ ì‘ìŒ
    - â†’ **bias amplification ì œê±° â†’ popularity bias ì˜í–¥ ì œê±°ë¨**

### **Global Popularity V.S. Local Popularity**

![image.png](attachment:582aa766-56c7-49e3-80bd-7c5c276d507b:image.png)

- ê° stageì— ëŒ€ì‘í•˜ëŠ” Popularity ê°’ì„ ì“°ëŠ” ê²ƒì´ ë” ì„±ëŠ¥ ì¢‹ìŒ.

## Performance of Adjusting Popularity (RQ2)

- (a): $\tilde{m_i}=m_i^T$
- (b): $\tilde{m_i}=m_i^T + \alpha\left(m_i^T-m_i^{T-1}\right)\quad (8)$ â†’ ë” ì„±ëŠ¥ ì¢‹ìŒ.

![image.png](attachment:248515d8-e3ff-44bf-9b39-eb2f6126b6c9:image.png)

### **More Refined Predictions for Popularity.**

- Uniformly split the data in the last training stage into ğ‘ sub-stages by time
- (a): $\tilde{m_i}=m_i^T$ ì‚¬ìš©.
- Nì´ ì¦ê°€í• ìˆ˜ë¡ ì„±ëŠ¥ ì¦ê°€í•˜ëŠ” ê²½í–¥ â†’ popularityë¥¼ ë” ì •ë°€í•˜ê²Œ ì˜ˆì¸¡í• ìˆ˜ë¡ ì„±ëŠ¥ í–¥ìƒ.
- *This experiment shows that the performance of PDA can be further improved with a more precise prediction of popularity.*

![image.png](attachment:c60310e9-7be7-4617-8a69-477105b3ecea:image.png)

### Total Improvements of PDA.

![image.png](attachment:eb6f4cb3-905b-4689-80fb-1c2733f3ee17:image.png)
