---
title: "[NeurIPS 2023] Estimating Propensity for Causality-based Recommendation without Exposure Data"
date: "2025-07-15"
date-modified: last-modified
description: "Exposure Data & Propensity Scores ì—†ì„ ë•Œì˜ Causality-based RS"
toc: true
number-sections: false
---
- References
    - **Paper**: [Estimating Propensity for Causality-based Recommendation without Exposure Data](https://proceedings.neurips.cc/paper_files/paper/2023/hash/a237f11d6aad94f59a182d70405d3fdb-Abstract-Conference.html)
    - **Official Code**: [GitHub Repository](https://github.com/mediumboat/PropCare)
    - **Conference**: [NeurIPS 2023](https://proceedings.neurips.cc/paper_files/paper/2023)

- [Paper download](NeurIPS'23-Estimating_Propensity_for_Causality-based_Recommendation_without_Exposure_Data.pdf)
- [Presentation Slides](NeurlIPS23-Estimating_Propensity_for_Causality-based_Recommendation_without_Exposure_Data.pdf)

# Abstract

- **Causality-based Recommendation Systems [RS]:**
    - **[Focus] item exposure [cause]â†’ user-item interactions [causal effects == result]**
    - â†” Conventional Correlation-based RS **ëŒ€í‘œì ì¸ ê³ ì „ RS ëª¨ë¸ ë…¼ë¬¸ ì°¾ì•„ë³´ê¸°**

---

- Existing Causality-based RS
: additional input[exposure data and/or propensity scores] í•„ìš” for training. **ì´ˆê¸° Causality-based RS ëª¨ë¸ ë…¼ë¬¸ ì°¾ì•„ë³´ê¸°**
    1. exposure data
    2. propensity scores == probability of exposure
    3. exposure data & propensity scores
- **[Problem]** Such data: often Not available in real-world situations b/c technical or privacy constraints
- **[Solution in this paper]**
    - **Propensity Estimation** for Causality-based Recommendation **(PROPCARE)**
    - **Only interaction data** ì‚¬ìš©. for training and inference
    - **[Method]** Relating the pairwise characteristics between propensity and item popularity
        
        â†’ Theoretical analysis on the *bias of the causal effect* under our model estimation.
        
        â†’ Empirically evaluate PROPCARE through both quantitative and qualitative experiments.
        

# 1. Introduction

<aside>
ğŸ’¡

**RSì˜ 4ê°€ì§€ paradigm**

1. Classical paradigm
    - [Limitation] Ignore the Causal Impact behind recommendation
2. Causality-based RS w/ observed [Exposure Data] or [Propensity Scores]
    - [Problem] Exposure Dataë¥¼ ì–»ì„ ìˆ˜ ì—†ìŒ.
3. Causality-based RS w/ observed [Exposure Data] but w/o [Propensity Scores]
    - Estimate propensity scores
    - Limitations
        1. ëŒ€ë¶€ë¶„ì˜ SOTA[state-of-the-art] methods: Propensity estimatorì„ í›ˆë ¨ì‹œí‚¤ê¸° ìœ„í•´ Exposure Dataê°€ í•„ìš”.
        2. Prior knowledgeë¥¼ propensity estimatorì— í†µí•© ì‹¤íŒ¨ â†’ Not robust estimation
4. Causality-based RS w/o observed [Exposure Data] and [Propensity Scores]
    - **Only interaction data** ì‚¬ìš©.
    - (propensity, item popularity) pairwise relationshipì„ prior knowledgeë¡œ í†µí•©
    â†’ more Robust Propensity Estimation
    - modelì— ì˜í–¥ì„ ì£¼ëŠ” factorsì— ëŒ€í•œ ë¶„ì„ ì œê³µ.
</aside>

- RS í™œìš©ë„: applications such as
    - streaming services
    - online shopping
    - job searching
- Primary aim of RS: boosting sales, user engagement, â€¦
    - â‡’ User Interactions(clicking or purchasing items)ì— ì˜ì¡´
    - **user-item interactions == clicking, purchasing**
        
        <aside>
        ğŸ’¡
        
        - Recommender Systemì—ì„œëŠ” Userì˜ ë°˜ì‘ì„ ì´ëŒì–´ ë‚´ëŠ” ê²ƒì´ ëª©ì ì´ë¯€ë¡œ, í´ë¦­ì´ë‚˜ êµ¬ë§¤ ë‘ ê°€ì§€ ìˆ˜ë‹¨ì„ interactionìœ¼ë¡œ ë¬¶ëŠ” ê²ƒ ê°™ë‹¤.
        - í â€¦ ê·¸ëŸ¬ë©´ ë‹¨ìˆœíˆ ëŠ¥ë™ì ì¸ í–‰ë™(í´ë¦­, êµ¬ë§¤)ì´ ì•„ë‹ˆë¼, just ë¨¸ë¦¬ ì†ìœ¼ë¡œë§Œ â€œì´ item ê´œì°®ì•„ë³´ì´ë„¤â€ ìƒê°ì„ ê°€ì§€ëŠ” ê²ƒì€ ì²´í¬í•˜ê¸° ì–´ë ¤ìš¸ ê²ƒ ê°™ìŒ.
        - ê²°êµ­ RSì—ì„œëŠ” Userê°€ Itemì— ëŒ€í•˜ì—¬ ë¬´ì–¸ê°€ ê°€ì‹œì ì¸ í–‰ë™ì„ í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ê²ƒ ê°™ë‹¤.
        </aside>
        

### Classical paradigm:

1. Predict user-item interactions
2. Interaction Probability â†’ Recommend items to users **ì°¸ê³ ë¬¸í—Œ [8, 22, 33, 35] ì°¸ì¡°.**
- [Limitation] Ignore the Causal Impact behind recommendation

### Recent Studies for **Causality-based Recommendation Systems [RS]**

- Treatments [Cause] â†’ Userâ€™s behavior [Result] **ì°¸ê³ ë¬¸í—Œ [38, 30, 28, 37] ì°¸ê³ **
    - **Treatments: Recommend/Expose the item or not**
    - **Behavior: Click or Purchase**
- Assumption (1): Recommending itemsì˜ ê´€ì ì—ì„œ,
    - With the higher causal effect > with the higher interaction probability.
- Userâ€™s behaviorì—ì„œì˜ Causal Effect ì •ëŸ‰í™” â† Observed data & Counterfactual treatment
- Assumption (2): Exposure Data or the Propensity Scoresê°€ training ë‹¨ê³„ì—ì„œ ê´€ì¸¡ê°€ëŠ¥.
    - **Exposure Data** == itemì´ userì—ê²Œ recommend ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
        - Exposure == Recommendation
    - **Propensity Scores** == userì—ê²Œ itemì´ recommending/exposingë  í™•ë¥ 
- [Problem] Exposure Dataë¥¼ ì–»ì„ ìˆ˜ ì—†ìŒ.
    - e.g. e-commerce platformì—ì„œ item êµ¬ë§¤ ì´ë ¥ì€ feasible.
        - But purchasesê°€ w/ exposureì¸ì§€ w/o exposureì¸ì§€ ì•Œ ìˆ˜ ì—†ìŒ. b/c technical and privacy constraints.
    - training ë‹¨ê³„ì—ì„œ exposure data and/or propensity scores ì—†ìŒ
        
        â†’ ê¸°ì¡´ì˜ causality-based recommenders [RS] ì‚¬ìš© ë¶ˆê°€.
        

### **[Solution in this paper] for Causality-based RS**

- Setup: Exposure and propensity scores: Not observable
- Some previous works: Estimate propensity scores â† e.g. addressing biases in recommendation **ì°¸ê³ ë¬¸í—Œ [38, 42, 1, 14, 21] ì°¸ì¡°.**
    - Limitations
        1. ëŒ€ë¶€ë¶„ì˜ SOTA[state-of-the-art] methods: Propensity estimatorì„ í›ˆë ¨ì‹œí‚¤ê¸° ìœ„í•´ Exposure Dataê°€ í•„ìš”.
        2. Prior knowledgeë¥¼ propensity estimatorì— í†µí•© ì‹¤íŒ¨ â†’ Not robust estimation
- [Paper Solution] New framework: PROPCARE
    - ê° userì˜ ê° itemì— ëŒ€í•œ propensity score, exposureë¥¼ estimation
    1. above limitations í•´ê²°
    2. data gap ë¬¸ì œ í•´ê²°
- Observation: (propensity scores, item popularity) pairwise characteristic
    - ì–¸ì œ? == user-item interactionì˜ í™•ë¥ ì´ ì˜ controlë  ë•Œ.
    - **Assumption 1**: probability of user-item interaction is well controlled.
    ****empirically validated in Sect. 4.2.
        - â†’ propensity estimationì„ ìœ„í•´ item popularityë¥¼ prior knowledgeë¡œ í¬í•¨ì‹œí‚´.
- Theoretical analysis on the bias of the estimated causal effect.
    - â†’ estimationì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” factorsë¥¼ ì•Œ ìˆ˜ ìˆìŒ.
    - â†’ model & experiment design.

### Previous Propensity Estimation  Vs  PROPCARE

![image.png](attachment:113d7608-9098-4029-9fa1-f6d54725397f:image.png)

- PROPCARE ì¥ì .
    1. Propensity or Exposure Dataê°€ ì „í˜€ í•„ìš”í•˜ì§€ ì•ŠìŒ.
    2. Prior Informationì„ Robust Estimationì— í¬í•¨ì‹œì¼œ ì‚¬ìš©.
- Paper Contributions
    1. Previous Causality-based RS: propensity score and/or exposure data are often unavailable but required for model training or inference.
    â†’ ì´ëŸ¬í•œ ë¬¸ì œ í•´ê²°.
    2. (propensity, item popularity) pairwise relationshipì„ prior knowledgeë¡œ í†µí•© â†’ more Robust Propensity Estimation
    3. modelì— ì˜í–¥ì„ ì£¼ëŠ” factorsì— ëŒ€í•œ ë¶„ì„ ì œê³µ.
    4. PROPCAREì˜ íš¨ê³¼ë¥¼ quantitative and qualitative ê²°ê³¼ë¥¼ í†µí•´ ê²€ì¦.

# 2. Related Work

<aside>
ğŸ’¡

**ì°¾ì•„ë³¼ ê²ƒ.**

- **A/B test**
- Naive Estimator **ì°¸ê³ ë¬¸í—Œ [30]** [RecSys'20: Unbiased Learning for the Causal Effect of Recommendation](https://dl.acm.org/doi/abs/10.1145/3383313.3412261)
- **Inverse Propensity Score (IPS) estimator ì°¸ê³ ë¬¸í—Œ [30] ì°¸ì¡°.**
- CausCF **ì°¸ê³ ë¬¸í—Œ [38] ì°¸ì¡°.**
- doubly robust estimator **ì°¸ê³ ë¬¸í—Œ [37] ì°¸ì¡°.**
- **Missing-Not-At-Random (MNAR) ë¬¸ì œê°€ ë°œìƒ.**  **ì°¸ê³ ë¬¸í—Œ [32] ì°¸ì¡°.**
- **Interaction modelsë¥¼ ì´ìš©í•˜ëŠ” approaches == click models ì°¸ê³ ë¬¸í—Œ [24, 3, 42, 21] ì°¸ì¡°.**
</aside>

## Causal effect estimation in recommendation

- Typical RS: positive feedback or interactions(clicks, purchases)ê°€ ì„±ê³µì ì¸ì§€ë¥¼ ê³ ë ¤
    - â†’ Recommendationsë¡œ ì¸í•œ causal effectë¥¼ ìµœì í™”í•˜ëŠ” ê²ƒì´ ë” ê°€ì¹˜ìˆë‹¤.
- Causal Effectë¥¼ êµ¬í•˜ëŠ” ê²ƒì˜ challenges
    - Online A/B tests: exposure strategiesë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŒ. But ë¹„ì‹¸ê³  selection biasì— ì·¨ì•½. **ì°¸ê³ ë¬¸í—Œ [27] ì°¸ì¡°.**
    - â†’ í•´ê²°ì±…: Causal Effect Estimators.
        1. Naive Estimator **ì°¸ê³ ë¬¸í—Œ [30] ì°¸ì¡°.**
        2. Inverse Propensity Score (IPS) estimator **ì°¸ê³ ë¬¸í—Œ [30] ì°¸ì¡°.**
            - propensity score := probability of exposure **ì°¸ê³ ë¬¸í—Œ [25] ì—ì„œ ì •ì˜.**
            - Non-parametric approach
        3. CausCF **ì°¸ê³ ë¬¸í—Œ [38] ì°¸ì¡°.**
            - Parametric models ì‚¬ìš©í•´ì„œ outcomes prediction.
        4. doubly robust estimator **ì°¸ê³ ë¬¸í—Œ [37] ì°¸ì¡°.**
            - parametric model + non-parametric IPS estimator â†’ bias and variance ê°ì†Œ.
        
        **â†’ ë¬¸ì œì : training stage ë‹¨ê³„ì—ì„œ propensity scores and/or exposure dataê°€ í•„ìš”í•¨.**
        

## Propensity estimation in recommendation

- Existing Causal Effect Estimation approaches
    - **ë¬¸ì œì  (1): training stage ë‹¨ê³„ì—ì„œ propensity scores and/or exposure dataê°€ í•„ìš”í•¨.**
    - **ë¬¸ì œì  (2): Missing-Not-At-Random (MNAR) ë¬¸ì œê°€ ë°œìƒ. ì°¸ê³ ë¬¸í—Œ [32] ì°¸ì¡°.**
    [KDD'10 Training and testing of recommender systems on data missing not at random](https://dl.acm.org/doi/abs/10.1145/1835804.1835895)
        
        ![image.png](attachment:abf34efb-6a34-4d8f-a880-0a0d91b4e088:image.png)
        
        - Romance moviesë¥¼ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒì€ romance moviesì—ë§Œ ìµœê³  ì ìˆ˜ 5ì ì„ ì£¼ê³ , horror moviesëŠ” í‰ê°€í•˜ì§€ ì•ŠìŒ.(ëˆ„ë½)
        - ê°™ì€ ë°©ì‹ìœ¼ë¡œ, horror moviesë¥¼ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒì€ horror moviesì—ë§Œ ìµœê³  ì ìˆ˜ 5ì ì„ ì£¼ê³ , romance moviesëŠ” í‰ê°€í•˜ì§€ ì•ŠìŒ.(ëˆ„ë½)
            - â†’ Missing (ëˆ„ë½): userê°€ ê°ì ì¢‹ì•„í•˜ê±°ë‚˜ ì•Œê³  ìˆëŠ” moviesë§Œ í‰ê°€
            - â†’ test setsì— MNAR ë¬¸ì œê°€ ë°œìƒ. í•­ìƒ user - item(movie)ì˜ pairê°€ ë³¸ì¸ì´ ì¢‹ì•„í•˜ëŠ” ì˜í™”ë§Œ pairë¡œ ìƒì„±.
            - â†’ (user, item)ì´ í•­ìƒ ìµœê³  ì ìˆ˜ 5ì ë§Œ ë°œìƒ, í•­ìƒ 5ì ì„ ì˜ˆì¸¡í•˜ëŠ” ì“¸ëª¨ ì—†ëŠ” ì¶”ì²œ ì‹œìŠ¤í…œ íƒ„ìƒ
            - â†’ [í•´ê²°ì±…] (user, item)ì—ì„œ ratings(í‰ê°€)ì´ observed or missing item ëª¨ë‘ì— ëŒ€í•˜ì—¬ prediction/rankingì„ í•´ì•¼ í•¨.
- Some methods: Estimate propensity in a **heuristic way [ê²½í—˜ì ì¸ ë°©ë²•]**
    1. Using item popularity **ì°¸ê³ ë¬¸í—Œ [30] ì°¸ì¡°.**
    2. Using other side Information. e.g., items participating in promotional campaigns **ì°¸ê³ ë¬¸í—Œ [28] ì°¸ì¡°.**
    
    **â†’ ë¬¸ì œì : Personalization ë¶€ì¡± & Noisy results.**
    
- Interaction modelsë¥¼ ì´ìš©í•˜ëŠ” approaches == click models **ì°¸ê³ ë¬¸í—Œ [24, 3, 42, 21] ì°¸ì¡°.**
    - propensity scores, relevance, interactionsê³¼ ê´€ê³„ìˆìŒ.
    - **ë¬¸ì œì : ì¶”ê°€ì ì¸ constraints ì—†ì´ëŠ” interaction model ë‹¨ë…ìœ¼ë¡œëŠ” optimizeí•˜ê¸° ì–´ë ¤ì›€. [Sect. 4.1.]**
- Matrix factorization, Linear regression, Dual learning, Double robust learning: propensity scores í•™ìŠµ ê°€ëŠ¥.
    - Exposure dataë¥¼ training labels or known variablesë¡œ ê°€ì •
    - â†’ **ë¬¸ì œì : Exposure dataê°€ í•„ìš”**

# 3. Preliminaries

## Data notations

- **Typical recommendation dataset**
    - $D = \{(Y_{u,i})\}$: collection of observed **training** user-item **interaction data**
- **Interactions between users-items.: Purchases or Clicks [Result]**
    - $Y_{u,i} \in \{0,1\}$: observed interaction
        - $Y_{u,i} = 1$: **user u interacted to item i**
    - User $u \in \{1, 2, 3,..., U\}$
    - Item $i \in \{1, 2, 3,..., I\}$
- **Unobservable indicator variable for Exposure [Cause]**
    - $Z_{u,i} \in \{0, 1\}$
        - **$Z_{u,i} = 1$: item i is exposed/recommended to user u**
- **Propensity score := probability of exposure**
    - $p_{u,i} := P\left(Z_{u,i}=1\right)$

## Causal effect modeling

- **Potential outcomes for different exposure statuses: $Z_{u,i} = 0 \ or \  1$**
    - ìœ—ì ì°¨: Exposure ì—¬ë¶€. [Cause]
    - ê°’: Interaction ì—¬ë¶€. [Result]
    - $Y_{u,i}^0 \in \{0,1\}$: **Exposure** âŒì¼ ë•Œì˜ interaction
    - $Y_{u,i}^1 \in \{0,1\}$: **Exposure â­•**ì¼ ë•Œì˜ interaction
    - **ë¬¸ì œì : real-worldì—ì„œëŠ” íŠ¹ì • (u,i)ì— ëŒ€í•˜ì—¬ $Y_{u,i}^0$ ë˜ëŠ” $Y_{u,i}^1$ë§Œ ê´€ì¸¡í•  ìˆ˜ ìˆìŒ. [Counterfactual Nature]** **ì°¸ê³ ë¬¸í—Œ [9] ì°¸ì¡°.**
- **Counterfactual Model**
    - Causal Effect: $\tau_{u,i} := Y_{u,i}^1-Y_{u,i}^0\in \{-1, 0, 1\}$ means **Exposure(Recommendation) â†’ Interaction Relationship**
        - $\tau_{u,i} = 1$: **recommending item i to user u** â‡’ user-item interaction ì¦ê°€.
            - 3ê°€ì§€ ì£¼ì²´(Users, Sellers, Platforms) ëª¨ë‘ positive causal effectsë¥¼ ê²°ê³¼ë¡œ í•˜ëŠ” recommendationìœ¼ë¡œë¶€í„° ì´ë“ì„ ì–»ìŒ.
            
            <aside>
            ğŸ’¡
            
            **RSì˜ ì£¼ì²´: User, Seller, Platform** 3ê°€ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¸ìš°ëŠ” ê²ƒ ê°™ë‹¤.
            
            </aside>
            
        - $\tau_{u,i} = -1$: **recommending item i to user u** â‡’ user-item interaction ê°ì†Œ.
        - $\tau_{u,i} = 0$: **recommending or not** â‡’ user-item interactionì— ì˜í–¥ì„ ë¼ì¹  ìˆ˜ ì—†ìŒ.

## Causal effect estimation

- Causal effect $\tau_{u,i}$: [Counterfactual Nature] ë•Œë¬¸ì— observed dataë¡œë¶€í„° directí•˜ê²Œ ê³„ì‚° ë¶ˆê°€ëŠ¥. â‡’ Estimation í•„ìš”.
    - $Y_{u,i}^1, Y_{u,i}^0$ì„ ë™ì‹œì— observationí•  ìˆ˜ ì—†ë‹¤.
- CausCF or Doubly robust estimator
    - direct parametric modelsë¼ì„œ potential outcomesì˜ prediction errorì— ë¯¼ê°
        - â†’ ê³ í’ˆì§ˆ labeled Exposure Data í•„ìš”. (for parametric models)
        - â†’ this paperì˜ setupì´ ì•„ë‹˜.
- **This paper**: IPS estimator $\in$ Non-parametric approach ì‚¬ìš©.
    - [**Appendix B**]
        
        $$
        \hat{Y}_{u,i}^1 = \frac{Z_{u,i} Y_{u,i}}{p_{u,i}}
        , \quad
        \hat{Y}_{u,i}^0 = \frac{\left(1-Z_{u,i}\right) Y_{u,i}}{1-p_{u,i}}
         \text{: Unbiased (IPS) Estimator}
        \\ \text{Since} \qquad 
        Y_{u,i}=Z_{u,i}Y_{u,i}^1 + \left(1-Z_{u,i}\right)Y_{u,i}^0 \quad (a.10)  
        \\
        \qquad \qquad \mathbb{E}\left[Z_{u,i}\right]= 1\cdot p_{u,i} + 0\cdot \left(1-p_{u,i}\right)=p_{u,i}
        $$
        
    
    $$
    \hat{\tau_{u,i}}^{IPS}= \hat{Y}_{u,i}^1 - \hat{Y}_{u,i}^0
     = \frac{Z_{u,i} Y_{u,i}}{p_{u,i}} - \frac{\left(1-Z_{u,i}\right) Y_{u,i}}{1-p_{u,i}}
     \text{: Also Unbiased Estimator} \quad (1)
    $$
    

<aside>
ğŸ’¡

IPS estimatorì—ì„œ ë” ë°œì „í•œ ì ì´ ë¬´ì—‡ì¸ê°€?

ë¬¸ì œì : training stage ë‹¨ê³„ì—ì„œ propensity scores and/or exposure dataê°€ í•„ìš”í•¨.

â†’ [í•´ê²°]: ì¶”ì •ì¹˜ ì‚¬ìš©í•˜ì—¬ ëŒ€ì²´í•˜ì˜€ìŒ. [Section 4.5]

- $p_{u,i} \rightarrow \hat{p_{u,i}}$
- $Z_{u,i} \rightarrow \hat{Z_{u,i}}$
</aside>

## Interaction model

- Assumption: Relationship betw. interactions, propensity and relevance

$$
y_{u,i} = p_{u,i} \times r_{u,i} \quad (2)
$$

- $y_{u,i}=P\left(Y_{u,i} =1\right)$: **Probability of interaction** betw. user u and item i [**Result: Interaction Prob.**]
- $p_{u,i} := P\left(Z_{u,i}=1\right)$: Propensity score := **probability** of exposure [**Cause: Exposure Prob.**]
- $r_{u,i}$: **Probability** that **item i** is **relevant** to **user u [Relevant Prob.]**

<aside>
ğŸ’¡

**Assumption: Interaction Prob. = Exposure Prob. * Relevant Prob.**

</aside>

# 4. Proposed Approach: PROPCARE

## 4.1. Naive propensity estimator

- **Setup: only interaction data** are observable
- Objective: Estimate propensity scores and exposure
    1. Main focus: Estimation of propensity scores $\hat{p_{u,i}}$
    2. â†’ Propensityë¡œë¶€í„° corresponding Exposureì€ ì‰½ê²Œ sampling ê°€ëŠ¥. using threshold. [Section 4.3]
- **Naive Loss Function** for the interaction model $y_{u,i} = p_{u,i} r_{u,i}$
    
    $$
    \mathcal{L}_{\text{naive}} = - Y_{u,i} \times \log f_p(\mathbf{x}_{u,i}; \Theta_p) f_r(\mathbf{x}_{u,i}; \Theta_r) - (1 - Y_{u,i}) \times \log(1 - f_p(\mathbf{x}_{u,i}; \Theta_p) f_r(\mathbf{x}_{u,i}; \Theta_r)) \quad (3)
    $$
    
    <aside>
    ğŸ’¡
    
    - Interaction model: $y_{u,i} = p_{u,i} r_{u,i}$
        - $\hat{p_{u,i}} = f_p \left(\mathbf{x_{u,i}};\Theta_p\right)$
        - $\hat{r_{u,i}} = f_r  \left(\mathbf{x_{u,i}};\Theta_r\right)$
        - â‡’ $\hat{y_{u,i}}=\hat{p_{u,i}} \times \hat{r_{u,i}}$
        - $\mathcal{L}_{\text{naive}} = - Y_{u,i} \times \log \hat{y_{u,i}} - (1 - Y_{u,i}) \times \log(1 -\hat{y_{u,i}})$
        : **Binary Cross-Entropy Loss ftn.** [  label*log (prob.) ] â‡’ **Point-wise manner**
    </aside>
    
    - $\mathbf{x}_{u,i} = f_e \left(u,i;\Theta_e\right)$: Joint user-item embedding output
        - $f_e$: learnable embedding function
        - $\mathbf{x}_{u,i}: f_p, f_r$ì˜ Inputìœ¼ë¡œ ì‚¬ìš©.
    - $f_p$: learnable propensity function â†’ Estimated propensity score $\hat{p_{u,i}}$
    - $f_r$: learnable relevance function â†’ Estimated relevance probability $\hat{r_{u,i}}$
    
    <aside>
    ğŸ’¡
    
    - Exposure Prob., Relevant Prob. ëª¨ë‘ êµ¬í•  ìˆ˜ ì—†ìŒ â†’ Estimation í•´ì„œ ì‚¬ìš©. with learnable function
    - [MLP] êµ¬ì¡°
        - [Input] (u,i) â†’ embedding vector ë³€í™˜ â†’ MLPë¡œ $\mathbf{x}_{u,i} = f_e \left(u,i;\Theta_e\right)$ [Output] ì¶œë ¥.
        $\Theta_e$: Weights of MLP ftn. $f_e$
        - [Input] $\mathbf{x}_{u,i}$ â†’ MLPë¡œ $\hat{p_{u,i}} = f_p \left(\mathbf{x_{u,i}};\Theta_p\right), \hat{r_{u,i}} = f_r  \left(\mathbf{x_{u,i}};\Theta_r\right)$ [Output] ì¶œë ¥.
        $\Theta_*$: Weights of MLP ftn. $f_*$
    - MLP: [Input] (u,i) â†’ $\hat{p_{u,i}} = f_p \left(\mathbf{x_{u,i}};\Theta_p\right), \hat{r_{u,i}} = f_r  \left(\mathbf{x_{u,i}};\Theta_r\right)$ [Output]
        - Exposure Prob., Relevant Prob. Estimation.
    </aside>
    
    - **Each learnable function $f_*$: parameterì„ ê°€ì§ â†’ $\Theta_*$: parameter set of $f_*$ â†’ MLPë¡œ parameter í•™ìŠµë¨.**
    - **ë¬¸ì œì : $\hat{y_{u,i}} = f_p \left(\mathbf{x_{u,i}};\Theta_p\right) \times f_r  \left(\mathbf{x_{u,i}};\Theta_r\right)$: $f_p$, $f_r$ì´ ê³±í•´ì§„ form**
        - **â†’ $\mathcal{L}_{\text{naive}}$ë¡œë¶€í„° $f_p$ or $f_r$ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ì—†ìŒ. $\hat{y_{u,i}}=\hat{p_{u,i}} \times \hat{r_{u,i}}$ê°€ í•™ìŠµë¨.**
        - **â†’ Propensity Score ì¶”ì • ë¶ˆê°€ëŠ¥. $\hat{p_{u,i}} = f_p \left(\mathbf{x_{u,i}};\Theta_p\right)$ì„ êµ¬í•  ìˆ˜ ì—†ìŒ.**

## 4.2. Incorporating prior knowledge

- **Naive Loss Functionì˜ í•´ê²°ë²•: Prior Knowledgeë¡œ $f_p$ or $f_r$ì„ constrain í•˜ëŠ” ê²ƒ.**
- *Observation: more popular items will have a higher chance to be exposed*  **[Popularity â†’ Exposure Prob.]**
    - $pop_i$: **Popularity** of **item i**
        
        $$
        pop_i := \frac{\sum_{u=1}^U Y_{u,i}}{\sum_{j=i}^I \sum_{u=1}^U Y_{u,j}}
        $$
        
        - ëª¨ë“  (user, item) pairs ì˜ interactions #ì¤‘, item iì— ëŒ€í•˜ì—¬ ì–¼ë§ˆë‚˜ ë§ì€ userê°€ interactionì„ í•˜ì˜€ëŠ”ê°€?
        - **Popularity of item i â‡’ ì „ì²´ interaction ì¤‘ item iì— ëŒ€í•œ ë¹„ì¤‘.**
    - ì§ê´€ì ì´ì§€ë§Œ popularity-exposure ê´€ê³„ë¥¼ ì„¤ëª…í•˜ê¸°ì— ì ì ˆí•˜ì§€ ëª»í•¨.
    - **â†’ ë°˜ë¡€**: ë†’ì€ interaction í™•ë¥ ì„ ê°€ì§„ item â‡’ ë†’ì€ ë…¸ì¶œ chanceë¥¼ ê°€ì§€ëŠ” ê²½í–¥ì´ ìˆìŒ.
        - **[Interaction Prob. â†’ Exposure Prob.]**
        - **[ë¬¸ì œì ]** **Popularity, Interaction Prob. â†’ Exposure Prob.**
        - Causal Effect: Exposure â†’ Interaction
            - Thus, Popularity factorì„ ì†Œê±°í•´ì•¼ í•¨.
    - **[í•´ê²°ì±…]** Popularityë¥¼ propensity/exposure estimationì— ëŒ€í•œ Prior Knowledgeë¡œ í†µí•©ì‹œí‚´.
        - â†’ Interaction Prob. control. â†’ **Assumption 1 (Pairwise Relationship on Popularity and Propensity)**

### **Assumption 1 (Pairwise Relationship on Popularity and Propensity) == Prior Knowledge**

<aside>
ğŸ’¡

1. Popularity
2. Interaction Prob. â†’ fixed. [control]
3. Exposure Prob. = Propensity

**Popularity â†’ Exposure Prob. ê´€ê³„**ë§Œì„ ë³´ê¸° ìœ„í•¨.

$\therefore$ **Prior Knowledge: ì¸ê¸°ê°€ ë§ì€ itemì´ ë…¸ì¶œì´ ë§ì´ ëœë‹¤. [Propensity í¬ë‹¤]**

</aside>

- user: u
- pair of items: (i, j)
- $pop_i > pop_j, \ y_{u,i} \approx y_{u,j}\  \Rightarrow \ p_{u,i} > p_{u,j}$
    - **ì •í™•íˆëŠ”, $y_{u,i} \approx y_{u,j} \ \Rightarrow \ \left( pop_i > pop_j\Leftrightarrow \ p_{u,i} > p_{u,j} \right )$
    : Popularity, Propensityì˜ ëŒ€ì†Œ ê´€ê³„ê°€ ê°™ë‹¤. if Interaction Prob. fixed.**

### Empirical validation of Assumption 1

Assumption 1ì„ ë§Œì¡±ì‹œí‚¤ëŠ” 3ê°€ì§€ dataset(DH_original, DH_personalized and ML)ì—ì„œì˜ ì‹¤í—˜ì  ê²€ì¦. by calculating

![Figure 2](attachment:68586a6a-6a74-4cb3-bc8c-4bcf6c706301:image.png)

Figure 2

- x-axis: bins [intervals]: **Inverse Similarity** in **Interaction Prob.** $|y_{u,j} - y_{u,i}|$
    - **ps. Inverse Similarity == Distance.**
- y-axis: $\text{ratio}_b$: ê° binì— ëŒ€í•˜ì—¬ Assumption 1ì„ ë§Œì¡±ì‹œí‚¤ëŠ” itemsì˜ í™•ë¥ 

<aside>
ğŸ’¡

$\left( |y_{u,j} - y_{u,i}| \downarrow \ \Rightarrow \ \text{ratio}_b \uparrow \right) \  \text{means}
\quad  \left[ y_{u,i} \approx y_{u,j} \ \Rightarrow \ \left( pop_i > pop_j\Leftrightarrow \ p_{u,i} > p_{u,j} \right ) \right]$

ì¦‰, Assumption 1ì´ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦ ë.

</aside>

1. Estimate $y_{u,i}$ from $Y_{u,i}$ using logistic matrix factorization **ì°¸ê³ ë¬¸í—Œ [11] ì°¸ì¡°.**
2. Obtain $p_{u,i}$ from ground truth values in the datasets
3. ê° userë³„ë¡œ item pairs (i,j)ì— ëŒ€í•˜ì—¬,  $|y_{u,j} - y_{u,i}|$ [Similarity in interaction prob.]ì„ ê¸°ì¤€ìœ¼ë¡œ ê° binì— ë°°ì¹˜
    - ì‹¤í—˜ì˜ ê°€ì • ìƒ $y_{u,i} \approx y_{u,j}$ ì´ë¯€ë¡œ, $|y_{u,j} - y_{u,i}|$ì€ 0.5 ê¹Œì§€ë§Œ ì‹¤í—˜.
4. $\text{ratio}_b$ ê³„ì‚°.
**user u**ì— ëŒ€í•˜ì—¬ **íŠ¹ì • bin b**ì— ì¡´ì¬í•˜ëŠ” **item pairs** ì¤‘ $pop_i > pop_j \Rightarrow \ p_{u,i} > p_{u,j}$ì„ ë§Œì¡±ì‹œí‚¤ëŠ” pairsì˜ ê°œìˆ˜. [í™•ë¥ ]

$$
ratio_b = \frac{1}{U} \sum_{u=1}^U \frac{\text{\# item pairs }(i,j) \text{ for user } u \text{ in bin } b \text{ s.t. } (p_{u,j} - p_{u,i})(\text{pop}_j - \text{pop}_i) > 0}{\text{\# item pairs }(i,j) \text{ sampled for user } u \text{ in bin } b}\quad (4)
$$

### Integrating prior knowledge

- $\mathcal{L_\text{naive}}$ì—ì„œ **$\hat{y_{u,i}}=\hat{p_{u,i}} \times \hat{r_{u,i}}$**ê°€ í•™ìŠµë¨ â†’ **$f_p$ or $f_r$ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë„ë¡,** ë¶„ë¦¬ëœ Loss function ì‚¬ìš©.
- $pop_i > pop_j, y_{u,i} \approx y_{u,j}$ì¼ ë•Œ, $f_p \left(\mathbf{x_{u,i}}\right) > f_p \left(\mathbf{x_{u,j}}\right)$ ì—¬ì•¼ í•¨. From. Assumption 1 [Prior Knowledge]
    
    $$
    \text{loss} = -\log\left[ \sigma\left( f_p \left(\mathbf{x_{u,i}}\right)-f_p \left(\mathbf{x_{u,j}}\right) \right) \right] \in \left(0, \infty \right) \quad (5)
    $$
    
    - $f_p \left(\mathbf{x_{u,i}}\right)-f_p \left(\mathbf{x_{u,j}}\right) \uparrow \ \Rightarrow \text{loss} \downarrow$: ë”°ë¼ì„œ lossë¥¼ minimizeí•˜ë ¤ëŠ” ë°©í–¥ì´ ìš°ë¦¬ì˜ Prior Knowledgeì— ì˜ ë¶€í•©í•œë‹¤.
        
        <aside>
        ğŸ’¡
        
        ì¶”ì¸¡ìœ¼ë¡œëŠ”, -log-likelihood functionì„ ë…¸ë¦° ê²ƒ ê°™ë‹¤. ì°¾ì•„ë³´ë©´ ìˆì„ ì§€ë„. ìœ ëª…í•œ ê¼´ ê°™ìŒ.
        
        í†µê³„í•™ì—ì„œ ë°°ì› ë“¯ì´ â€œloss functionì„ minimize í•˜ëŠ” ê²ƒ == log-likelihood functionì„ maximize í•˜ëŠ” ê²ƒ.â€
        
        ì´ë¼ì„œ, loss functionì„ â€œ-log-likelihood functionâ€ìœ¼ë¡œ ë§ì´ ì¡ê¸° ë•Œë¬¸.
        
        </aside>
        
    - $\sigma$: Sigmoid function.
    - loss: pair-wise ë°©ì‹ìœ¼ë¡œ popularityë¥¼ ì˜ ì‚¬ìš©í–ˆìŒ.
- Above $\text{loss}$ì˜ Advantages
    1. $f_p, f_r$ ë¶„ë¦¬
    2. Interaction dataìœ¼ë¡œ ê³„ì‚°ì´ ê°€ëŠ¥í•œ item popularityë§Œ ì‚¬ìš©. â† $pop_i := \frac{\sum_{u=1}^U Y_{u,i}}{\sum_{j=i}^I \sum_{u=1}^U Y_{u,j}}$
    3. $pop_i \neq pop_j$ì´ë¯€ë¡œ ì˜ˆì¸¡ê°’ $\hat{p_{u,i}} \approx 0 \ \text{or}\  1$ ë°©ì§€. [Section 4.5ì˜ Remark 2]
- **Final Popularity-loss function: Popularity â†’ Exposure Prob.** $\hat{p_{u,i}}$ **[Assumption 1]**
    
    $$
    \mathcal{L}_{\text{pop}} = -\kappa_{u,i,j} \log \left[ \sigma(\text{sgn}_{i,j} \cdot (f_p(\mathbf{x}_{u,i}) - f_p(\mathbf{x}_{u,j}))) + \sigma(\text{sgn}_{i,j} \cdot (f_r(\mathbf{x}_{u,j}) - f_r(\mathbf{x}_{u,i}))) \right] \quad (6)
    \\
    \arg\min_{\Theta_\text{pop}} \mathcal{L_\text{pop}} = \hat{\Theta_{\text{pop}}} \ \rightarrow \  \hat{p_{u,i}}, \hat{r_{u,i}}
    $$
    
    <aside>
    ğŸ’¡
    
    For a Fixed $y_{u,i}$,
    
    - $\hat{p_{u,i}} = f_p \left(\mathbf{x_{u,i}}\right)$
    - $\hat{r_{u,i}} = f_r  \left(\mathbf{x_{u,i}}\right)$
    
    $$
    \mathcal{L}_{\text{pop}} = -\kappa_{u,i,j} \times \log \left[ \sigma(\text{sgn}_{i,j} \cdot (\hat{p_{u,i}}) - \hat{p_{u,j}}))) + \sigma(\text{sgn}_{i,j} \cdot (\hat{r_{u,j}} - \hat{r_{u,i}})) \right] \quad (6')
    $$
    
    - **Popularity â†’ Exposure Prob. â†’ Relevance Prob.: ìœ„ loss functionì€ ê²°êµ­ popularityì— ì˜ì¡´ [**$\mathcal{L}_{\text{pop}}$**]**
    </aside>
    
    1. $sgn_{i,j} = \text{sign}\left(pop_i - pop_j\right) \in \{1, -1\}$: $pop_i > pop_j, pop_i < pop_j$ ëª¨ë‘ ê³ ë ¤.
    2. $\kappa_{u,i,j} = e^{\eta\left(y_{u,i}-y_{u,j}\right)^2}, \eta<0$: weighting function. $|y_{u,i}-y_{u,j}| \downarrow \ \ \Rightarrow \ \kappa_{u,i,j} \uparrow$
        - $\eta$: learnable parameter
        - Assumption 1ì˜ ì¡°ê±´ì— ë¶€í•©í• ìˆ˜ë¡ lossì˜ ê°€ì¤‘ì¹˜ë¥¼ í¬ê²Œ ë§Œë“¦.: $y_{u,i} \approx y_{u,j}$ ì¡°ê±´ ê³ ë ¤.
    3. Interaction model: $y_{u,i} = p_{u,i} \times r_{u,i}$ â‡’ for a fixed $y_{u,i}$,  $p_{u,i} \uparrow \ \ \Rightarrow r_{u,j} \downarrow$
        - $f_p$ ë§Œ ê³ ë ¤í•˜ì§€ ì•Šê³ , $f_r$ê¹Œì§€ ê³ ë ¤. â†’ model trainingì„ ë” í–¥ìƒì‹œí‚´.
        - ë’· ë¶€ë¶„ relevance termì´ ***j - i*** ì¸ ì´ìœ . $p_{u,i} \uparrow \ \ \Rightarrow r_{u,j} \downarrow$

## 4.3. Propensity learning

1. **$\mathcal{L_\text{naive}}:\hat{y_{u,i}}=\hat{p_{u,i}} \times \hat{r_{u,i}}$ê°€ í•™ìŠµë¨ â†’ Interaction model $y_{u,i} = p_{u,i} \times r_{u,i}$ ìµœì í™”**
2. $\mathcal{L}_{\text{pop}}:\hat{p_{u,i}},\hat{r_{u,i}}$**ê°€ í•™ìŠµë¨. [Pairwise-loss]** â†’ **Popularity**ë¥¼ **Propensity learning**ì„ ìœ„í•œ **Prior information**ìœ¼ë¡œ ì‚¬ìš©.
    
    â†’ í†µí•©ì‹œí‚¨ total loss function. $\mathcal{L_\text{total}}$ ì‚¬ìš©í•˜ì.
    
3. Propensity score $\hat{p_{u,i}}$ Regularization for [$\hat{p_{u,i}} \approx 0 \ \text{or}\  1$ ë°©ì§€].
    
    â†’ **Regularization Term: $\mu \cdot \text{KLD}\left(Q \| \text{Beta}(\alpha, \beta)\right)$, Regularization parameter:** $\mu$
    
    $$
    \mathcal{L_\text{total}} = \sum_{u,i,j} \left(\mathcal{L}_{\text{naive}} + \lambda \cdot\mathcal{L}_{\text{pop}}\right) + \mu \cdot \text{KLD}\left(Q \| \text{Beta}(\alpha, \beta)\right) \quad (7)
    \\
    \arg\min_{\Theta_{\text{total}}} \mathcal{L_\text{total}} = \hat{\Theta_{\text{total}}} \ \rightarrow \  \hat{p_{u,i}}, \hat{r_{u,i}}
    $$
    
    - ì†Œìˆ˜ì˜ ì¸ê¸° ì•„ì´í…œë§Œ ë…¸ì¶œí™•ë¥ ì´ í¬ê¸° ë•Œë¬¸ì—, propensity scores [**ground-truth**]ëŠ” **long-tailed distribution**.
        - â†’ ë§ˆì°¬ê°€ì§€ë¡œ long-tailedì¸ **Beta distribution**ì„ propensity scoresì˜ regularizationì— ì‚¬ìš©.
        [ì„ í–‰ì—°êµ¬: **ì°¸ê³ ë¬¸í—Œ [4, 15] ì°¸ì¡°.**]
        - $Q$: Empirical distribution of all estimated propensity scores $\hat{p_{u,i}}$
        - $\alpha, \beta$: parameters which are selected to simulate a long-tailed shape.
        - **$\text{KLD}\left(\cdot \| \cdot\right)$: Kullback-Leibler Divergence betw. two distributions. â†’ ì‘ì„ìˆ˜ë¡ ì˜ˆì¸¡ ë¶„í¬ì™€ ì‹¤ì œ ë¶„í¬ê°€ ë¹„ìŠ·í•¨.**
    - $\lambda, \mu$: trade-off hyper-parameters [weighting term.]
        - $\lambda: \mathcal{L_\text{naive}}, \mathcal{L}_{\text{pop}}$ ì¡°ìœ¨.
        - $\mu$: Regularization ì¡°ìœ¨.
    - Estimated propensity score $\hat{p_{u,i}}$ â†’ $\hat{Z_{u,i}}$ ì˜ˆì¸¡.
        - $\hat{Z_{u,i}}=1 \quad if \ \ \text{Norm}\left(\hat{p_{u,i}}\right) \geq \epsilon$
        - $\hat{Z_{u,i}}=0 \quad \text{otherwise}$
        - $\epsilon$: threshold hyper-parameter
        - $\text{Norm}$: Normalization function such as Z-score normalization
    - Algorithms [in Appendix A]: update all learnable parameters based on the total loss
        
        ![image.png](attachment:fcf89e5a-4448-4fd1-ab4a-a9b728eeda4c:image.png)
        

<aside>
ğŸ’¡

- [Input] $D = \{(Y_{u,i})\} \rightarrow \mathcal{L}_{\text{total}} \rightarrow \hat{p_{u,i}}, \hat{r_{u,i}} \rightarrow \hat{Z_{u,i}}$ [Output]
- $\hat{r_{u,i}}$ë„ í•¨ê»˜ êµ¬í•  ìˆ˜ ìˆì§€ë§Œ, ì‹¤ì œ PROPCARE frameworkì—ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ.
</aside>

## 4.4. Causality-based recommendation

- **DLCE: Debiased Learning for the Causal Effect ì°¸ê³ ë¬¸í—Œ [30] ì°¸ì¡°. â†’ DLCE lossê°€ ì¶©ë¶„íˆ ì´í•´ë˜ì§€ ì•ŠìŒ..**
    - **SOTA [state-of-the-art] Causality-based Recommender w/ IPS estimator**
    - Input: Interaction $Y_{u,i}$, Exposure $Z_{u,i}$, Propensity $p_{u,i}$
    - **Output: Ranking Score $\hat{s_{u,i}}$ for each user-item (u,i) pair**
        - User uë¥¼ ìœ„í•œ Recommendation Rankingì„ ì •í•  ë•Œ ì‚¬ìš©ë˜ëŠ”, each itemì˜ Ranking Score.
    - Given $(u, i, j) \quad s.t. \  i \neq j$, the **DLCE loss function**
        
        $$
        \mathcal{L}_{\text{DLCE}}= \frac{Z_{u,i}Y_{u,i}}{\max(p_{u,i},\chi^1)} \log \left(1+e^{-\omega(\hat{s_{u,i}}-\hat{s_{u,j}})}\right) + \frac{(1-Z_{u,i})Y_{u,i}}{\max(1-p_{u,i},\chi^0)} \log \left(1+e^{\omega(\hat{s}_{u,i}-\hat{s}_{u,j})}\right) \quad (8)
        $$
        
        $$
        \mathcal{L}_{\text{DLCE}}= \frac{Y_{u,i}}{\max(p_{u,i},\chi^1)} \log \left(1+e^{-\omega(\hat{s}_{u,i}-\hat{s}_{u,j})}\right) \times \mathbb{I} \left(Z_{u,i}=1\right)
        \\ \qquad  \qquad \qquad \ + \ 
         \frac{Y_{u,i}}{\max(1-p_{u,i},\chi^0)} \log \left(1+e^{\omega(\hat{s}_{u,i}-\hat{s}_{u,j})}\right) \times \mathbb{I} \left(Z_{u,i}=0\right) \quad (8)
        $$
        
        $$
        \hat{s_{u,i}} = f_s \left(u,i,\Theta_s\right), \quad
        \arg\min_{\Theta_{s}} \mathcal{L_\text{DLCE}} = \hat{\Theta_{s}} \ \rightarrow \  \hat{s_{u,i}}
        $$
        
        - $\chi^1, \chi^0, \omega$: hyper-parameters
    - **[This paper] Ground truth ëŒ€ì‹  ì¶”ì •ì¹˜ ì‚¬ìš©.**
        - $p_{u,i} \rightarrow \hat{p_{u,i}}$
        - $Z_{u,i} \rightarrow \hat{Z_{u,i}}$
        
        $$
        \mathcal{L}_{\text{PC-DLCE}}= \frac{\hat{Z_{u,i}}Y_{u,i}}{\max(\hat{p_{u,i}},\chi^1)} \log \left(1+e^{-\omega(\hat{s_{u,i}}-\hat{s_{u,j}})}\right) + \frac{(1-\hat{Z_{u,i}})Y_{u,i}}{\max(1-\hat{p_{u,i}},\chi^0)} \log \left(1+e^{\omega(\hat{s_{u,i}}-\hat{s_{u,j}})}\right) \quad \left(8'\right)
        $$
        
        $$
        \hat{s_{u,i}} = f_s \left(u,i,\Theta_s\right), \quad
        \arg\min_{\Theta_{s}} \mathcal{L_\text{PC-DLCE}} = \hat{\Theta_{s}} \ \rightarrow \  \hat{s_{u,i}}
        $$
        
        - PC: PROPCARE

<aside>
ğŸ’¡

**DLCE**: [Input] $Y_{u,i}, \hat{p_{u,i}}, \hat{Z_{u,i}} \rightarrow \hat{s_{u,i}}$ [Output]

</aside>

<aside>
ğŸ’¡

**PROPCARE Structure**

- [Input] $D = \{(Y_{u,i})\} \rightarrow \hat{s_{u,i}}$ [Output]
- User uì— ëŒ€í•˜ì—¬, $\{\hat{s_{u,1}}, \hat{s_{u,2}}, \ldots, \hat{s_{u,I}}\}$ë¥¼ sortingí•˜ì—¬ ê°€ì¥ í° ìƒìœ„ Kê°œ ì„ ë°œ.
    - â†’ Top-K Recommendation Lists. [Final Output]
</aside>

## 4.5. Theoretical property

- ê¸°ì¡´ Causal Effectì˜ IPS estimator: Unbiased Estimator.
    
    $$
    \hat{\tau_{u,i}}^{IPS}=\frac{Z_{u,i} Y_{u,i}}{p_{u,i}} - \frac{\left(1-Z_{u,i}\right) Y_{u,i}}{1-p_{u,i}} \text{: Unbiased Estimator} \quad (1)
    $$
    
- **[This paper] Ground truth ëŒ€ì‹  ì¶”ì •ì¹˜ ì‚¬ìš©. â†’ IPS estimator: Biased Estimator.**
    - $p_{u,i} \rightarrow \hat{p_{u,i}}$
    - $Z_{u,i} \rightarrow \hat{Z_{u,i}}$
    
    $$
    \hat{\tau_{u,i}}^{PC-IPS}=\frac{\hat{Z_{u,i}} Y_{u,i}}{\hat{p_{u,i}}} - \frac{\left(1-\hat{Z_{u,i}}\right) Y_{u,i}}{1-\hat{p_{u,i}}} \text{: Biased Estimator} \quad (1')
    $$
    

### Proposition 1

$$
\text{bias}\left(\hat{\tau_{u,i}}^{PC-IPS}\right)=
\left( \frac{p_{u,i}+\mathbb{E}\left[ \hat{Z_{u,i}}-Z_{u,i} \right]}{\hat{p_{u,i}}} -1 \right) Y_{u,i}^1
-
\left( \frac{1-p_{u,i}-\mathbb{E}\left[ \hat{Z_{u,i}}-Z_{u,i} \right]}{\hat{1-p_{u,i}}} -1 \right) Y_{u,i}^0 \ \quad (9)
$$

### Remark 1

$\text{bias}\left(\hat{\tau_{u,i}}^{PC-IPS}\right)$ì˜ major factors:

$$
\frac{p_{u,i}}{\hat{p_{u,i}}}, \  \frac{1-p_{u,i}}{1-\hat{p_{u,i}}}, \  \mathbb{E}\left[ \hat{Z_{u,i}}-Z_{u,i} \right] \quad
 \ \rightarrow \quad \left( \hat{p_{u,i}}=p_{u,i}, \ \hat{Z_{u,i}}=Z_{u,i} \ \Rightarrow \text{bias}\left(\hat{\tau_{u,i}}^{PC-IPS}\right)=0\right)
$$

### Remark 2

$$
\hat{p_{u,i}} \approx \text{0 or 1} \ \Rightarrow \ \text{bias}\left(\hat{\tau_{u,i}}^{PC-IPS}\right) \approx \pm \infty
$$

- **Exposure variable**: $Z_{u,i} \in \{0, 1\}$ is **Binary variable**. â†’ **F1 scoreê°™ì€ binary classification metrics ì‚¬ìš©.**
    - $\mathbb{E}\left[ \hat{Z_{u,i}}-Z_{u,i} \right] \rightarrow\text{bias}\left(\hat{\tau_{u,i}}^{PC-IPS}\right)$ì´ë¯€ë¡œ $\hat{Z_{u,i}}$ë¥¼ ì˜ ì¶”ì •í• ìˆ˜ë¡ biasê°€ ì‘ì•„ì§.
- **Propensity**: $p_{u,i} := P\left(Z_{u,i}=1\right)$ is **Continuous variable. â†’ KLD, Kendallâ€™s Tauê°™ì€ metrics ì‚¬ìš©.** [Section 5.2]
    - Remark 2ì—ì„œ $\hat{p_{u,i}} \not\approx \text{0 or 1}$ì´ì–´ì•¼ í•¨. â†’ Eq. (7)ì²˜ëŸ¼ **Regularization ì‚¬ìš©**í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.

# 5. Experiment

- PROPCAREê°€ quantitative & qualitative experiments ëª¨ë‘ì—ì„œ íš¨ê³¼ì ì„ì„ ë³´ì¸ë‹¤.

## 5.1. Experiment setup

### Datasets

- 3ê°€ì§€ standard Causality-based Recommendation Benchmarks: **DH_original, DH_personalized, MovieLens 100K (ML 100K)**
- **DH_original, DH_personalized** $\in$ DunnHumby dataset
    - purchase and ptomotion logs @ ì˜¤í”„ë¼ì¸ ì†Œë§¤ì , 93ì£¼ ê¸°ê°„ë™ì•ˆ.
    - DH_original: ì£¼ê°„ ì „ë‹¨ì§€ â†’ Exposure â†’ ground-truth Propensity Scores
    - DH_personalized: Simulation â†’ ground-truth Propensity Scores
- **ML 100K**
    - Usersâ€™ Rating on movies
    - Simulated Propensity Scores â† ratings & user behaviors
- PROPCARE: ground-truth propensity scores â†’ Model Output Evaluationì—ë§Œ ì‚¬ìš©.
    - Note: training ë‹¨ê³„ì—ì„œ ground-truth values ì‚¬ìš© âŒ
- Datasets â†’ training/validation/test sets
    - Statistics: number or average values of Key variables [User, Item, Observed Interaction, Exposure, Causal Effect, Propensity]
    
    ![image.png](attachment:1eed134b-181b-43d3-bda6-cb8322c5de6d:image.png)
    

### Baselines

- PROPCARE  vs  Baselines [other methods]
- Propensity Estimators
    - **Ground-truth values: propensity $p_{u,i}$, exposure $Z_{u,i}$ â†’ input of DLCE on training**
        1. **Ground-truth**: datasets â†’ Propensity Score & Exposure values
    - **Estimate propensity $\hat{p_{u,i}}$ â†’ Derive exposire $\hat{Z_{u,i}}$ â†’ input of DLCE on training**
        1. **Random**: Propensity Scores $\in \left(0, 1\right)$ randomly
        2. Item Popularity (**POP**): Propensity Scores = Normalization of POP $\in \left(0, 1\right)$
        3. **CJBPR**: Propensity â†’ Relevance â†’ Propensity â†’ Relevance â†’ â€¦ point-wise optimization
        4. **EM**: Expectation-Maximization algorithm â†’ Propensity Scores point-wise learning

### Parameter settings

- Validation data â†’ Tuning hyper-parameters
    - PROPCARE: Use the trade-off hyper-parameters as
        - $\lambda = 10$
        - $\mu=0.4$
    - Other settings: Appendix C.2.

### Evaluation metrics

- **Performance** of Causality-based Recommendation â†’ Evaluation metrics [Appendix C.3.]
    1. **CP@10, CP@100**: Causal effect-based Precision (CP)
    2. **CDCG**: Causal effect-based Discounted Cumulative Gain (CDCG)
    
    $$
    \text{CP@K} = \frac{1}{U} \sum_{u=1}^{U} \sum_{i=1}^{I} \frac{\mathbf{1}(\text{rank}_u(\hat{s}_{u,i}) \le K)\tau_{u,i}}{K} \quad (a.11)
    \\ \text{CDCG} = \frac{1}{U} \sum_{u=1}^{U} \sum_{i=1}^{I} \frac{\tau_{u,i}}{\log_2 (1 + \text{rank}_u(\hat{s}_{u,i}))}  \quad (a.12)
    $$
    

## 5.2. Results and discussions

- PROPCARE > Baselines: additional experiments in [ Appendix D. ]

### Performance comparison

- PROPCARE > Baselines in two aspects
    1. The **downstream causality-based recommendation** using the estimated propensity and exposure
    2. The accuracy of the estimated propensity and exposure

![image.png](attachment:c7eb3a1f-4dfd-4a16-9341-2793df3286f4:image.png)

- **Performance** of Causality-based Recommendation [Evaluation metrics ë¹„êµ.]
- Ground-truth: performance ê°€ì¥ ì¢‹ë‹¤. [Evaluation metrics ê°€ì¥ í¼.]
    - ì‹¤ì œ propensity, exposure valuesë¥¼ DLCEì— ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸.
        - â†’ But real-worldì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€.
    - PROPCARE: ê°€ì¥ Ground-truth ê°’ì— ê°€ê¹Œì›€. íŠ¹íˆ DH_personalizedì—ì„œëŠ” í° ì°¨ì´ âŒ
    - PROPCARE > CJBPR, EM
        - â†’ Pairwise method by Assumption 1.ì´ ì¢‹ë‹¤.

![image.png](attachment:178c32e0-5c81-40ab-8a84-bdca379185dd:image.png)

- Propensity, Exposure Estimation Accuracy
- POP: Baselines ì¤‘ì—ì„œ, Kendallâ€™s Tau ê¸°ì¤€ ê°€ì¥ ì¢‹ë‹¤.
    - But Table 2ë¥¼ ë³´ë©´ POPì˜ causality metricsëŠ” ì¢‹ì§€ ëª»í•¨.
        - KLD ê°’ì´ í° ê²ƒìœ¼ë¡œ ë³´ì•„, propensity scoreì˜ distribution ì˜ˆì¸¡ì´ ì˜ ë˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸. â†’ ill-fit propensity distribution.
    - F1 scoreê°€ ì‘ìŒ â†’ Exposure estimationë„ ì˜ ë˜ì§€ ëª»í•˜ì˜€ìŒ.
- PROPCARE: F1 score, KLDì—ì„œ íš¨ê³¼ê°€ ì¢‹ìŒ & Table 2ì—ì„œ causality metricsë„ ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸.
    - Tau scoresê°€ ë‹¤ë¥¸ baselinesë³´ë‹¤ ì•½ê°„ ë‚˜ì˜ì§€ë§Œ, ë‚˜ë¨¸ì§€ ë‘ ì§€í‘œê°€ ì¢‹ìŒ.
        - â†’ Propensity Score, Exposure ë‘˜ ëª¨ë‘ estimation ì˜ë¨. â†’ Causal Performance ì¢‹ìŒ.
- Causality-based Recommendation: multiple factorsì— ì˜í•˜ì—¬ ì˜í–¥ì„ ë°›ìŒ.
â†’ **influencing factorsê°€ ë¬´ì—‡ì´ ìˆëŠ”ê°€? [5.2. ë§ˆì§€ë§‰ ë‹¨ë½]**

### Ablation study

$$
\mathcal{L}_{\text{pop}} = -\kappa_{u,i,j} \log \left[ \sigma(\text{sgn}_{i,j} \cdot (f_p(\mathbf{x}_{u,i}) - f_p(\mathbf{x}_{u,j}))) + \sigma(\text{sgn}_{i,j} \cdot (f_r(\mathbf{x}_{u,j}) - f_r(\mathbf{x}_{u,i}))) \right] \quad (6)
$$

<aside>
ğŸ’¡

$\mathcal{L}_{\text{pop}}$ì˜ termë¥¼ ë³€í™”ì‹œì¼°ì„ ë•Œ, PROPCAREì— ë¹„í•˜ì—¬ ì„±ëŠ¥ì´ ë§ì´ ë–¨ì–´ì§ â†’ ë³€í™”ëœ termì´ ì¤‘ìš”í•œ termì´ë‹¤.

</aside>

- Derive 5 variants
    1. **NO_P**: ***Removing the constraint on estimated $\hat{p_{u,i}}$*** by deleting the term with $f_p(\mathbf{x}_{u,i}) âˆ’ f_p(\mathbf{x}_{u,j})$
    2. **NO_R**: ***Removing the constraint on estimated $\hat{r_{u,i}}$***  by deleting the term with $f_r(\mathbf{x}_{u,j}) âˆ’ f_r(\mathbf{x}_{u,i})$
    3. **NO_P_R**: ***Removing $\mathcal{L}_{\text{pop}}$*** entirely from the overall loss $\mathcal{L}_{\text{total}}$ to eliminate Assumption 1 altogether
    4. **NEG**: Reversing Assumption 1 by ***replacing $\text{Sgn}_{i,j}$ with $-\text{Sgn}_{i,j}$*** to assume that more popular items have smaller propensity scores
        - ***Removing the condition*** $\left( pop_i > pop_j\Leftrightarrow \ p_{u,i} > p_{u,j} \right )$
    5. $\kappa=1$: Setting all $\kappa_{u,i,j} = 1$ â†’ equal weighting of all training triplets.
        - ***Removing the condition $y_{u,i} \approx y_{u,j}$***
    
    ![image.png](attachment:2b10f4fd-68c2-48aa-a125-b552b2777a29:image.png)
    
    - x-axis: dataset
    - y-axis: performance
    - PROPCARE: best performance
    - NEG: worst performance â†’ Assumption 1 is most important.
    
    <aside>
    ğŸ’¡
    
    Importance:
    
    1. $\left( pop_i > pop_j\Leftrightarrow \ p_{u,i} > p_{u,j} \right )$
    2. $\mathcal{L}_{pop}$
    3. $y_{u,i} \approx y_{u,j}$
    4. $\hat{p_{u,i}}$
    5. $\hat{r_{u,i}}$
    </aside>
    

### Effect of regularization

$$
\mathcal{L_\text{total}} = \sum_{u,i,j} \left(\mathcal{L}_{\text{naive}} + \lambda \cdot\mathcal{L}_{\text{pop}}\right) + \mu \cdot \text{KLD}\left(Q \| \text{Beta}(\alpha, \beta)\right) \quad (7)
\\
\arg\min_{\Theta_{\text{total}}} \mathcal{L_\text{total}} = \hat{\Theta_{\text{total}}} \ \rightarrow \  \hat{p_{u,i}}, \hat{r_{u,i}}
$$

- Regularization parameter: $\mu$
    
    ![image.png](attachment:7ed34733-6b47-4d74-a585-c8e5deddeed5:image.png)
    
    - $\mu \approx 0 \  \Rightarrow \ \text{performance CDCG} \downarrow$
    - $\mu \uparrow \  \Rightarrow \ \text{performance CDCG} \uparrow, \quad \mu_{\text{peak}} \in \left[0.2, 0.8\right]$

### Factors influencing causality-based recommendation

- **ë°©ë²• 1: ground-truth propensity or exposure valuesì— Noises Injection [ê°ê° (b), (a)]**
    
    <aside>
    ğŸ’¡
    
    Estimation Accuracy  Vs  Causality-based Recommendation Performance**: Important Factors**
    
    Propensity Score - Estimation Accuracy  Vs  Exposure - Estimation Accuracy
    
    </aside>
    
    ![image.png](attachment:3fe0d2eb-3463-41b3-9a57-d62a7615a1f1:image.png)
    
    - (a) Ground-truth propensity scores $p_{u,i}$ë¥¼ DLCE trainingì— ì‚¬ìš©í•˜ë©´ì„œ, $Z_{u,i}$ë¥¼ $0â†”1$ë¡œ ì¼ë¶€ë¶„ randomly flip.
    **[$Z_{u,i}$ ì˜¤ì—¼.]**
        - x-axis: Flip ratio
        - y-axis: CDCG performance
        - ì˜¤ì—¼ ë¹„ì¤‘ì´ ì»¤ì§ˆ ìˆ˜ë¡ ì„±ëŠ¥ ê¸‰ê²©íˆ í•˜ë½.
            - â†’ Causality-based Recommendation: Exposureì˜ Estimationì— ë§¤ìš° ë¯¼ê°.
            
            <aside>
            ğŸ’¡
            
            **Exposure - Estimation Accuracyê°€ ë” ì¤‘ìš”í•˜ë‹¤.**
            
            </aside>
            
    - (b) Ground-truth exposure $Z_{u,i}$ë¥¼ DLCE trainingì— ì‚¬ìš©í•˜ë©´ì„œ, Add Gaussian Noises to the propensity scores.
    **[$p_{u,i}$ ì˜¤ì—¼.]**
        - x-axis: Variance of Noises
        - y-axis: CDCG performance
        - ì˜¤ì—¼ ë¹„ì¤‘ì´ ì»¤ì§ˆ ìˆ˜ë¡ ì„±ëŠ¥ ì ë‹¹íˆ í•˜ë½.
            - â†’ Causality-based Recommendation: Propensity Scoreì˜ Estimationì— ì ë‹¹íˆ ë¯¼ê°.
- **ë°©ë²• 2: Correlation betw. Estimation Accuracy & Recommendation Performance**
    
    <aside>
    ğŸ’¡
    
    Estimation Accuracy  Vs  Causality-based Recommendation Performance **: Correlation**
    
    </aside>
    
    - Dataset: Only DH_original dataset [3ê°œì˜ dataset ì¤‘ ê·¸ëƒ¥ í•˜ë‚˜ ë½‘ì€ ë“¯í•¨.]
        
        ![image.png](attachment:dc73b9be-c5b3-4b55-b433-e8cd6523de81:image.png)
        
        - x-axis: Estimation Accuracy
            - KLD, Kendallâ€™s Tau: Propensity Scores
            - F1 score: Exposure
        - y-axis: CDCG performance [Recommendation Performance]
        
        <aside>
        ğŸ’¡
        
        1. $\text{KLD} \downarrow \ \Rightarrow \ \text{CDCG} \uparrow$
        : Estimated Propensity Scores $\hat{p_{u,i}}$ ë¶„í¬ê°€ long-tailedì¸ beta ë¶„í¬ì™€ ë¹„ìŠ·í• ìˆ˜ë¡ Performance good.
        2. $\text{Kendallâ€™s Tau} \uparrow \ \Rightarrow \ \text{CDCG} \uparrow$
        3. $\text{F1 score} \uparrow \ \Rightarrow \ \text{CDCG} \uparrow$
        </aside>
        

## 5.3. Case study

- PROPCARE: Ranking-based Recommendation
    
    ![image.png](attachment:8c00ee71-67b0-4c21-87a0-86cc6020430d:image.png)
    
    - Top-5 Recommend items [User ID 2308, DH_personalized dataset]
    1. **Ground-truth: DLCEê°€ ranking listë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•˜ì˜€ìŒ.**
        - Most itemsê°€ Positive Causal Effect.
            - $\tau_{u,i} := Y_{u,i}^1-Y_{u,i}^0 = 1$
            - â†’ **Recommending item i to user u** â‡’ user-item interaction[click or purchase] ì¦ê°€.
        - All items in positive causal effect: ëª¨ë‘ purchased ë˜ì—ˆìŒ. â†’ Goal of Causality-based Recommendation ì„±ê³µ.
    2. **CJBPR, PROPCARE: Purchased itemsì˜ Causal EffectsëŠ” ê°ê¸° ë‹¤ë¥´ë‹¤.**
        - **CJBPR - strawberries:** causal effect âŒ
            - **Recommending or not â‡’ user-item interaction[Purchasing]ì— ì˜í–¥ì„ ë¼ì¹  ìˆ˜ ì—†ìŒ.**
        - **PROPCARE - infant soy**: Positive causal effect
            - **Recommending item i to user u â‡’ user-item interaction[click or purchase] ì¦ê°€.**
    3. **POP: Negative Causal Effectë¥¼ ê°€ì§„ item(tortilla chips)ë„ recommendë¥¼ í•œë‹¤.**
        - **â†’ POP: ì¢‹ì€ methodê°€ ì•„ë‹˜.**

# 6. Conclusion

- PROPCARE: w/o ground-truth of propensity and exposure data
- Observation of (propensity scores, item popularity) â†’ Key Assumption â†’ Prior Information â†’ Causality-based RS
- Factors for bias in estimated causal effects
- Empirical studies: PROPCARE > Baselines [other methods]
- Future research suggestion:
    1. Direct exposure estimation w/o propensity scores [i.e, w/o propensity estimation]
    2. Parametric causal effect estimators [IPS estimator: Non-parametric approach]

---

---
