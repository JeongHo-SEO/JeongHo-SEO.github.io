---
title: "[ICDE 2023] Influential Recommender System"
date: "2025-07-22"
date-modified: last-modified
description: "influence pathë¥¼ í†µí•œ objective item ìœ ë„: active recommendation"
toc: true
number-sections: true
---
- References
    - **Paper**: [Influential Recommender System](https://ieeexplore.ieee.org/abstract/document/10184767)
    - **Conference**: [ICDE 2023](https://ieeexplore.ieee.org/xpl/conhome/10184508/proceeding)

- [Presentation Slides](Presentation-Slides/ICDE2023-Influential_Recommender_System.pdf)

# Abstract + I. Introduction

## User-oriented Recommender System (URS)

- Traditional Recommender Systems
- Userâ€™s historical interests [internal interests]
â†’ RS recommends to adapt the userâ€™s current interests
: Passive Recommendation

### **Goal** in commercial applications

- Userâ€™s interestsë¥¼ í™•ì¥ì‹œì¼œì„œ userê°€ ëª°ëê±°ë‚˜ ê´€ì‹¬ì—†ë˜ itemsë¥¼ Acceptí•˜ê²Œ ë§Œë“œëŠ” ê²ƒ.
â†’ Customer[user] Interactionsë¥¼ ì¦ê°€ì‹œí‚¬ ë°©ì•ˆì´ í•„ìš”.
â†’ URS: Userâ€™s interests ë‚´ì—ì„œë§Œ Recommendationì´ ì´ë£¨ì–´ì§€ë¯€ë¡œ ë¶ˆê°€ëŠ¥.
â†’ **IRS ì œì•ˆ.**

## Influential Recommender System (IRS)

### Concepts

- User $u$, item $i$
1. Objective Item ì„¤ì •.: Target item, $i_t$
2. Influence path ì„¤ì •.: Sequential list of carefully selected items

â†’ userâ€™s historical interests ë§Œì¡± & userâ€™s interestsë¥¼ $i_t$ë¡œ í™•ì¥.

â†’ Userê°€ given objective itemì„ ì¢‹ì•„í•˜ë„ë¡ ìœ ë„.: Active Recommendation

### Example with watching movies

![**FIg. 1.ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.**
Tomì˜ ì‹¤ì„ ì´ The Matrixì—ë„ ê°€ì•¼í•˜ê³ , The Matrixê°€ Cameronì— ì˜í•´ directedë˜ì—ˆì–´ì•¼ í•©ë‹ˆë‹¤.
ë”°ë¼ì„œ **Tom: Expedition: Bismarck â†’ The Matrix â†’ The Abyss ì—¬ì•¼ í•©ë‹ˆë‹¤.**](attachment:3c97553a-9e50-4640-9560-99665fa12ab9:image.png)

**FIg. 1.ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.**
Tomì˜ ì‹¤ì„ ì´ The Matrixì—ë„ ê°€ì•¼í•˜ê³ , The Matrixê°€ Cameronì— ì˜í•´ directedë˜ì—ˆì–´ì•¼ í•©ë‹ˆë‹¤.
ë”°ë¼ì„œ **Tom: Expedition: Bismarck â†’ The Matrix â†’ The Abyss ì—¬ì•¼ í•©ë‹ˆë‹¤.**

- Interest ëŒ€ìƒ (3ê°€ì§€)
    - Genre: Fantasy, Romance
    - Director: Cameron
- Arrows
    - Solid arrows [ì‹¤ì„ ]: Usersâ€™ viewing histories
    â†’ usersâ€™ chronological behavioral sequences
    - Dash arrows [ì ì„ ]: Usersâ€™ influence path
- Objective item for user **Eric**: **The Notebook**
    - Influence Path: Inception â†’ The Matrix **â†’ The Abyss â†’ The Terminator â†’ Avatar â†’ Titanic â†’ The Notebook**
    1. Only Fantasy
    2. Tomê³¼ movie ê²¹ì¹¨ â†’ Tomâ€™s watching historyë¥¼ recommendation
    : Fantasy + Cameron
    â†’ Fantasy + Cameron + Romance
    â†’ Cameron + Romance
    3. Jennyì™€ movie ê²¹ì¹¨ â†’ Jennyâ€™s watching historyë¥¼ recommendation
    : Cameron + Romance
    â†’ **Romance: Objective item**

### Challenges

1. Influence Path
    1. Userâ€™s historical interestì—ì„œ ë„ˆë¬´ ë§ì´ ë²—ì–´ë‚˜ë©´ ì•ˆë¨. for userâ€™s trust and satisfaction
    2. Objective itemì— ê´€ê³„ëœ ì¶”ì²œì„ í•´ì•¼ í•¨.
2. Generation of influence path
    - itemsê°„ì˜ sequential dependenciesì— ë¶€í•©í•´ì•¼ í•¨.
    - ì¦‰, next item/actionì€ userê°€ ìµœê·¼ì— ì°¸ì—¬í•œ items/actionsì— ë”ìš± ì˜ì¡´í•´ì•¼ í•¨.
3. Userâ€™s preference for external influence
    - Userë§ˆë‹¤ ì™¸ë¶€ ì˜í–¥ì— ëŒ€í•œ ì„ í˜¸ê°€ ë‹¤ë¦„. ì¦‰, personalí•¨.
        1. Extrovertí•œ, external influencesì— ì‰½ê²Œ ì‹œë„í•˜ëŠ” user
            
            â†’ influence pathê°€ more aggressiveí•  ìˆ˜ ìˆìŒ.
            
        2. New interestsë¥¼ ì„¤ë“í•˜ê¸° ì–´ë ¤ìš´ user
            
            â†’ influence pathë¥¼ ë” ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ í•´ì•¼ í•¨.
            
    - Impressionability: External influenceì— ëŒ€í•˜ì—¬ userë§ˆë‹¤ ì„œë¡œ ë‹¤ë¥¸ preferenceë¥¼ ê°€ì§.

---

**í•´ê²°ì±… â†’ IRN framework including PIM**

### Influential Recommender Network (IRN)

- **Challenge 2**: Itemâ€™s sequential dependenciesë¥¼ encoding í•´ì•¼ í•¨.
    1. User-Item interaction sequence: sequential êµ¬ì¡°.
    & NLP sentences: sequential êµ¬ì¡°.
    2. Itemsê°„ì˜ dependencies: ì¸ì ‘í•˜ê±°ë‚˜ ë©€ë¦¬ ìˆëŠ” items ëª¨ë‘ ê³ ë ¤.
    & Wordsê°„ì˜ dependencies: ì¸ì ‘í•˜ê±°ë‚˜ ë©€ë¦¬ ìˆëŠ” words ëª¨ë‘ ê³ ë ¤.
    
    â†’ NLPì˜ Transformer modelê³¼ íŠ¹ì„±ì´ ìœ ì‚¬.
    
    **â†’ Transformer-based sequential modelì„ êµ¬ì¶•. == IRN framework**
    
- **Challenge 3**: Each userë§ˆë‹¤ ê°œì¸í™”ëœ influence path í•„ìš”.
    
    â†’ Item attention weights ê³„ì‚°í•  ë•Œ, user embeddingì„ ë„£ì–´ì•¼ í•¨.
    
    **â†’ Personalized Impressionability Mask (PIM)**
    

### Evaluation metrics for IRNâ€™s performance

- IRSì™€ ê´€ë ¨ëœ ê¸°ì¡´ ì—°êµ¬ê°€ ì—†ìŒ. â†’ í‰ê°€ ì²™ë„ í•„ìš”. â†’ designí•´ì„œ ì‚¬ìš©.
- IRSê°€ userâ€™s satisfactionì„ ìœ ì§€ì‹œí‚¤ë©´ì„œ userâ€™s interestë¥¼ objective itemìœ¼ë¡œ í™•ì¥ì‹œì¼°ëŠ”ê°€?

### Evaluator

- ì–¼ë§ˆë‚˜ ë§ì€ userê°€ unseen itemì— ê´€ì‹¬ì„ ê°€ì¡ŒëŠ”ì§€ í‰ê°€ í•„ìš”.
â†’ offline datasetì—ì„œ obtain ë¶ˆê°€.
â†’ unseen itemì— ëŒ€í•œ userì˜ reactionì„ simulation í•´ì•¼ í•¨.
â†’ **Evaluator**

### Contribution

1. Given objective itemì— ëŒ€í•˜ì—¬ userì—ê²Œ pro-actively lead [active recommendation]
2. Challenges í•´ê²°.: IRN framework
3. Performance Metrics design & IRN Performance: better than baseline recommenders

# II. Related Work

## A. Bayesian Persuasion

### Persuasion

- Def.: Influencing behavior via the provision of information.
    - info. â†’ (provider) â†’ influence to (someone)â€™s behavior
- Abstraction:
    - info. â†’ (sender) â†’ influence to (receiver)â€™s behavior
- In RS:
    - Influence path â†’ (recommender) â†’ user becomes to like the objective item

### Bayesian Persuasion

- Persuasion problem related to Bayesian manner
- Social learning, Products advertisement, Matching marketsâ€¦ ë“± real-world scenariosì— ì ìš©ë¨.
- Domain Knowledge í•„ìš”

### IRN

- Data â†’ Designing influence path w/ proper ML techniques
    - data-driven manner
    - Domain Knowledge í•„ìš” ì—†ìŒ.
- **RSë¥¼ persuasion behaviorê³¼ í†µí•©ì‹œì¼°ìŒ.**

## B. Sequential Recommendation System

### Sequential Recommender System (SRS)

- **Input: Sequential signals [IRSì™€ì˜ ê³µí†µì ]**
- Output: Next-item recommendation
- **Challenges**
    1. Higher-order sequential dependencies í•™ìŠµ
        1. Lower-order sequential: simple â†’ Markov chain or factorization machinesë¡œ modeling
        2. Higher-order sequential: complex â†’ RNN, graph-based models
    2. Handling user-item interaction sequences **w/ flexible order and noise**
        1. CNN, Attention modelsë¡œ í•´ê²°
    3. Handling user-item interaction sequences **w/ heterogeneous relations and hierarchical structures**
        1. Mixture modelsë¡œ í•´ê²°

### SRS vs IRS

- SRS: Itemsâ€™ sequential dependencies â†’ next-item recommendationì— ì‚¬ìš©.
    - SRS $\subset$ URS
- IRS: sequential dependency information â†’ influence paths generationì— ì‚¬ìš©. for objective item
    - IRS $\not \subset$ URS

# III. Influential Recommender System

## A. Problem Definition

![image.png](attachment:34412680-7d38-466a-b852-d762ccd32481:image.png)

- IRSë§Œì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ë©´,
    - Input: $s_h \oplus s_p$
    - output: ìµœì¢… $s_p$

### Notation

- Item set: $I=\{ i_1, i_2, \ldots, i_{|I|} \}$
- User set: $U=\{ u_1, u_2, \ldots, u_{|U|} \}$

---

- íŠ¹ì • user uì— ëŒ€í•œ, User-Item interaction sequence: $s^u=\{ i_1, i_2, \ldots, i_{m} \} \in S_u$
    - Watching Movieë¼ê³  í•˜ë©´, ì‹œê°„ì˜ íë¦„ $t_1, t_2, \ldots, t_m$ì— ëŒ€í•œ movies ìˆœì„œ sequence
    - Movie == item, watching = interaction
- íŠ¹ì • user uì— ëŒ€í•œ, set of $s$: $S_u$
- ëª¨ë“  (user,item)ì— ëŒ€í•œ, interaction sequence set: $S = \cup_{u=1}^{|U|} S_u = \{ s_1,s_2, \ldots, s_{|S|} \}$

---

- íŠ¹ì • user uì— ëŒ€í•œ,
    - userâ€™s viewing history: $s_h^u=\{ i_1, i_2, \ldots, i_{q-1} \}$ means userâ€™s original interests
    - Influence path: $s_p^u = \{ i_j, i_{j+1}, \ldots, i_k \}$
    - Objective item: $i_t^u$ means target item for user u

### Algorithm

- Assumption: Simplicityë¥¼ ìœ„í•´, userê°€ ëª¨ë“  recommendationsì„ acceptí•œë‹¤ê³  ê°€ì •
    - ì›ë˜ëŠ” userê°€ recommendationì„ ë³´ê³  item accept or rejectë¥¼ ê²°ì •
- $\mathcal{F}$: Recommender function â†’ learning í•„ìš”.
- $s_p$: ì´ˆê¸°ì—” empty set â†’ ì ì°¨ ì±„ì›Œì§.

![**í•™ìŠµì´ ì™„ë£Œëœ í›„, ìµœì¢… $\mathcal{F}$ë¥¼ algorithm 1ì— ì‚¬ìš©í•¨.**](attachment:48981f67-9810-45c8-9304-376ca9c59d58:image.png)

**í•™ìŠµì´ ì™„ë£Œëœ í›„, ìµœì¢… $\mathcal{F}$ë¥¼ algorithm 1ì— ì‚¬ìš©í•¨.**

## B. Path-finding Algorithms as IRS

<aside>
ğŸ’¡

Influence path generation == path-finding problem in Graph

</aside>

- $S_u$ë¡œë¶€í„° graphë¥¼ ê·¸ë ¤ì•¼ í•¨.
- $s_h$ì˜ last itemì„ $i_h$ë¼ê³  í•˜ë©´, $i_h$ëŠ” userì˜ recent interestì„.
- $i_h$ì™€ $i_t$ ì‚¬ì´ì˜ pathë¥¼ ì°¾ì•„ì•¼ í•¨. â†’ path-finding algorithm ì‚¬ìš©.
- ê°€ì¥ ë¨¼ì € ì†Œê°œëœ path-finding algorithm: Pf2Inf
- Pf2Inf algorithm example
    
    ![image.png](attachment:14e962de-7ff4-484c-875f-e08be1880aac:image.png)
    
    - $s_h = \{, \ldots,i_1\}, \ i_t = i_{11}$ì¼ ë•Œ, shortest pathë¥¼ influence pathë¡œ ì°¾ìŒ.
        - $s_p = \{ i_1, i_6, i_4, i_{11} \}$
    

## C. Adapting Existing RS with Greedy Search

### Pf2Inf ë‹¨ì .

1. $s_h$ì—ì„œ itemsì˜ sequential patternsë¥¼ êµ¬í•  ìˆ˜ ì—†ë‹¤.
2. Sparse recommendation datasetì—ì„œ, disjoint graphsê°€ ë°œìƒí•œë‹¤.
    
    ![image.png](attachment:62acd4a7-05ac-4130-bc3b-96104490f10f:image.png)
    
    ì´ ê²½ìš° $s_h=\{i_3, i_4, i_{10}\}, i_t=i_{12}$ì¼ ë•Œ, ì ì ˆí•œ $s_p$ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤.
    

### Pf2Infâ€™s Alternative = Rec2Inf

- Greedy search strategy
1. Given $s_h$, use existing RS $\mathcal{R}$ â†’ generate top-k recommendations set $\mathcal{R}_k = \mathcal{R}\left(s_h \oplus s_p \right)$
2. Item embedding â† e.g. item2vec
3. Calculate distance betw. item $i \in \mathcal{R}_k$ and objective item $i_t$
4. Choose the closest item $i'$ and then Add $i'$ into the $s_p$
5. Repeat 1 - 4
    
    **â†’ End if**  $i_t$ is added into the $s_p$
    

### Rec2Infâ€™s Limitations

1. ê° iterationì—ì„œ distanceê°€ minimumì¸ item í•˜ë‚˜ì”© $s_p$ë¡œ ë”í•´ì§.
â†’ local optimal selection
â†’ global optimal influence pathë¼ê³  í•  ìˆ˜ ì—†ìŒ.
2. Objective item $i_t$ê°€ training processì—ëŠ” í¬í•¨ë˜ì§€ ì•ŠìŒ.
â†’ RSê°€ ì´ë¥¸ ì‹œê¸°ì— ê³„íšë  ìˆ˜ ì—†ìŒ. 

<aside>
ğŸ’¡

[ëª©í‘œ] Influence Path $s_p$ ì°¾ê¸°.

- B & Cì—ì„œ ì‹œë„í–ˆë˜ graph-based model
    
    â†’ path-finding problemì´ ì˜ í•´ê²°ë˜ì§€ ì•ŠìŒ.
    
    â†’ graph-based model í¬ê¸°.
    
- ë‹¤ë¥¸ ë°©ë²•? â†’ N.N-based IRN.
</aside>

## D. Influential Recommender Network (IRN)

![image.png](attachment:aa598382-595a-4f1f-b864-9c5ca34b821b:image.png)

### Framework

1. Embedding layer: input sequence â†’ input vector
    
    ![image.png](attachment:6a194465-4e79-45f0-87b8-4eb86e74d185:image.png)
    
2. L decoder layers: ê°ê° self-attention layer ì¡´ì¬, with Personalized Masking
    
    ![image.png](attachment:be484634-2080-411b-b98c-b5e8091f4c0e:image.png)
    
3. Output layer: hidden states â†’ í™•ë¥ ë¶„í¬
    
    ![image.png](attachment:530faaeb-9dcf-43fa-8622-45e1290144c3:image.png)
    

### 1) Item Embedding

![image.png](attachment:6a194465-4e79-45f0-87b8-4eb86e74d185:image.png)

- Embedding: item[discrete token] â†’ vector [output]
- ì´ ë•Œ transformer êµ¬ì¡°ì—ì„œ ordering propertyë¥¼ ì‚´ë¦¬ê¸° ìœ„í•´, Positional Encoding í•„ìš”.
    
    $$
    \mathbf{e}\left(i_j\right) = \text{TE}\left[i_j\right] + \text{PE}\left[j\right]\in \mathbb{R}^d \quad  \text{for}\  j=1,\ldots,m \quad (1)
    $$
    
    - $\text{TE} \in \mathbb{R}^{|I| \times d}$: Token Embedding matrix [Item embedding]
    - $\text{PE} \in \mathbb{R}^{m \times d}$: Positional Embedding matrix [Positional Encoding]
- Pre-trained embedding by item2vec model â†’ better initial weights â†’ better model performance

### 2) Decoder

- Lê°œì˜ layers, input â†’ 1st layer â†’ 2nd layer â†’ â€¦ â†’ L-th layer â†’ output
    - First decoder layerâ€™s input: $\mathbf{H}^0 =\{\mathbf{e}\left(i_1\right),\ldots,\mathbf{e}\left(i_m\right)\}$
    - Embedding sequence $\mathbf{H}^0$ â†’ Sequence of hidden states $\mathbf{H}^L=\{\mathbf{h}_1^L,\ldots,\mathbf{h}_m^L\}$
- **PIMì„ ê³ ë ¤í•˜ì§€ ì•Šì•˜ì„ ê²½ìš°, [Not personalized]**
    - $\mathbf{h}_j$: hidden state of $i_j$ â† [history, target] $i_1, i_2, \ldots, i_{j-1}, i_t$
        
        $$
        \mathbf{h}_j=\text{Dec}\left(\mathbf{h}_{<j}, \mathbf{h}_t\right) \quad (2)
        $$
        
    - Each decoder layer: $(l-1)^{th}$ layerê°€ $l^{th}$ layerë¥¼ update.
        
        $$
        \mathbf{H}^l=\text{Self-Attn}\left(\mathbf{H}^{l-1}\right)\quad(3)
        $$
        
    - **But, ì‹ (3)ì€ í‹€ë¦° ì‹ì¸ ê²ƒ ê°™ìŒ. Add&Norm, FFNì´ ê³ ë ¤ë˜ì§€ ì•ŠìŒ. in Fig. 4.**
    - **ìˆ˜ì •í•œ ì‹.**
        
        $$
        \mathbf{H}^l
        =\text{FFN}\left(
        \text{AddNorm}\left(
        \text{Self-Attn}\left(
        \mathbf{H}^{l-1}
        \right)
        \right)
        \right) \quad(3')
        $$
        
    - ë˜í•œ ìœ„ êµ¬ì¡°ì—ì„œ Query, Key, ValuesëŠ” ëª¨ë‘ ê°™ì€ ê°’ì„ ì‚¬ìš©.
        
        $$
        \text{Self-Attn}\left(\mathbf{H}^l\right)=\text{Attention}\left(\mathbf{H}^l,\mathbf{H}^l,\mathbf{H}^l\right)
        \\
        \qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad(4)
        \\
        \text{Attention}\left(\mathbf{Q},\mathbf{K},\mathbf{V}\right)=\left[\text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}}\right)\right]^T \mathbf{V}
        $$
        
        - $\mathbf{Q}$: Query vector
        - $\mathbf{K}$: Key vector
        - $\mathbf{V}$: Value vector
- Personalized Impressionability Mask (PIM)
    - self-attention layerì— ì‚½ì…
    1. Which items can be seen by the attention layer
    2. to what extent the item will be aggregated to produce the hidden states

### 3) Perceiving objective

- PIM: standard attention maskì˜ í™•ì¥
    
    â†’ decoderê°€ previous items & objective item ëª¨ë‘ ì¸ì§€í•˜ê²Œ ë§Œë“¦.
    
    ![image.png](attachment:393919e9-9708-4b2f-897c-851387c9423d:image.png)
    
- $w_t$: mask weight for $i_t$
- $w_h$: mask weight for preceding history.
    - j-th row: Only $i_1, \ldots, i_j$ predicts $i_{j+1}$.
- $w_t > w_h$: $i_t$ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬. â†’ $w_t$ê°’ì„ ì¡°ì •í•¨ìœ¼ë¡œì„œ IRNì˜ ê³µê²©ì ì¸ ì •ë„ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŒ. [ì‚¬ëŒì— ë”°ë¼ ê³µê²©ì ìœ¼ë¡œ ìœ ë„í•˜ëŠ” ë“±.]

### 4) Personalized Impressionability Factor

![image.png](attachment:36fe9f3c-e6a4-4744-a0b6-ec0cebb7f3a1:image.png)

- Usersë§ˆë‹¤ external influenceì— ëŒ€í•œ acceptanceê°€ ë‹¤ë¦„. [Personalized Curiousness of exploration]
    - â†’ IRNì˜ aggressive ì •ë„ ì¡°ì ˆ â†” $w_t$ ì¡°ì •.
    
    $$
    \mathbf{e}\left(u\right)=\mathcal{U}\left[u\right]
    \\
    r_u=\mathbf{W}^U\mathbf{e}\left(u\right)\quad (5)
    $$
    
    - $\mathbf{e}\left(u\right)\in \mathbb{R}^{d'}$: embedding of user u
    - $\mathcal{U}$: user embedding matrix
    - $\mathbf{W}^U$: parameters of the linear transformation
- ê¸°ì¡´: history & target
    
    ![image.png](attachment:93baa4a4-f0d0-4cc0-bcee-e70bf31486c6:image.png)
    
- paper: Personalized term ë„£ì–´ì„œ PIM ì‚½ì…. user-termì¸ $r_u$ë¥¼ ê³±í•˜ì—¬, $w_t \times r_u$ì‚¬ìš©.
    
    ![image.png](attachment:12415231-38b2-4f6e-85da-69cb4395efcb:image.png)
    
- **PIM ê³ ë ¤í•œ ìµœì¢… ì‹.**
    
    $$
    \mathbf{h}_j=\text{Dec}\left(\mathbf{h}_{<j}, \mathbf{h}_t, r_u\right) \quad
    \\
    \mathbf{H}^l=\text{Self-Attn}\left(\mathbf{H}^{l-1}, r_u\right) \quad (*)
    \\
    \mathbf{H}^l
    =\text{FFN}\left(
    \text{AddNorm}\left(
    \text{Self-Attn}\left(
    \mathbf{H}^{l-1}, r_u
    \right)
    \right)
    \right)
    \\\text{for} \ l=1,\ldots,L \quad(6)
    $$
    
    - ë§ˆì°¬ê°€ì§€ë¡œ, $(*)$ì€ í‹€ë¦° ì‹ ê°™ìŒ. (6)ìœ¼ë¡œ ìˆ˜ì •.

### 5) Pre-padding Input Sequences

- item sequences â†’ lengthsê°€ ëª¨ë‘ ë‹¤ë¦„. â†’ paddingì´ í•„ìš”.
- post-padding ëŒ€ì‹  pre-padding ë°©ì‹ ì‚¬ìš©.
- e.g. pre-padding vs post-padding
    - Maximum sequence length = 5
    - item sequences = $\{i_1, i_2, i_3\}$
        - pre-padded sequence = $\{PAD, PAD, i_1, i_2, i_3\}$
        - post-padded sequence = $\{ i_1, i_2, i_3,PAD, PAD\}$
        - $PAD$: padding token
- **Pre-padding: $i_t$ì˜ positionì´ fixed. b/c last item in sequence â†’ ì•ˆì •ì .**
- Post-padding: sequence lengthì— ë”°ë¼ $PAD$ê°œìˆ˜ê°€ ë‹¬ë¼ì§€ë¯€ë¡œ, $i_t$ì˜ position ë³€ë™.

### 6) Output Probability

![image.png](attachment:530faaeb-9dcf-43fa-8622-45e1290144c3:image.png)

$$
p\left(i_j|i_{<j}, i_t, u\right)=\text{softmax}\left(\mathbf{W}^p \mathbf{h}_{j-1}^L\right) \quad (7)
$$

- $\mathbf{W}^p \in \mathbb{R}^{|I|\times d}$: projection matrix
- IRNâ€™s Recommendation: probability dist. $p\left(i_j|i_{<j}, i_t, u\right)$ â†’ item generating â†’ influence path. at each step.

### 7) Objective Function

for user u,

- sequence of items $s=\{i_1,\ldots,i_m\} \in S_u$
- If actual path $s$ â†’ $P\left(s|i_t, u\right)$: maximized
- $\text{PPL}\left(s|i_t, u\right):=P\left(s|i_t,u\right)^{-\frac{1}{m}}$: minimized
    
    $$
    \text{PPL}\left(i_1,\ldots,i_m|i_t, u\right)
    =\left(
    \prod\limits_{j=1}^m
    P\left(i_j|i_{<j},i_t,u\right)
    \right)^{-\frac{1}{m}}\quad (8)
    $$
    
- Computingì„ ìœ„í•´ $\text{PPL}\left(s|i_t, u\right) \downarrow  \ \Rightarrow \log{\text{PPL}\left(s|i_t, u\right)}\downarrow$ë¥¼ ì‚¬ìš©í•˜ì—¬,
    
    $$
    \text{log}\text{PPL}\left(i_1,\ldots,i_m|i_t, u\right)
    =-\frac{1}{m}
    \sum\limits_{j=1}^m
    \text{log}P\left(i_j|i_{<j},i_t,u\right):\text{minized}
    $$
    
- ë”°ë¼ì„œ Loss functionìœ¼ë¡œ Cross-Entropy loss ì‚¬ìš©.
    
    $$
    \mathcal{L}=\frac{1}{|S|}\sum\limits_{u\in U}\sum\limits_{s \in S_u}
    \left(
    \sum\limits_{j=1}^m
    \text{log}P\left(i_j|i_{<j},i_t,u\right)\right)\quad (9)
    $$
    
    - $S=\cup_{u=1}^{|U|} S_u$ì´ë¯€ë¡œ, ëª¨ë“  userê°€ ê³ ë ¤ë¨.
    - Each user: multiple sequences ê°€ëŠ¥.

# IV. Experiment

## A. Datasets

### 1) Preprocessing

### 2) Dataset Splitting

## B. IRS Evaluation

### 1) Objective Item Selection

### 2) Evaluation Metrics

![image.png](attachment:ea4291fc-3d8d-40b8-b9e5-35ef37f25e5e:image.png)

![image.png](attachment:259d7ecf-f261-47d1-ba3e-e41b7e75b5e1:image.png)

![image.png](attachment:74fe9547-363f-4f38-b418-deb47ad0979f:image.png)

### 3) IRS Evaluator

![image.png](attachment:81cd4b47-2c05-45b4-81e8-9f28f985e80b:image.png)

## C. Baselines

## D. Experiment Result

![image.png](attachment:f8335ba4-8cd2-4b22-88b2-b83afda5aaa0:image.png)

### 1) Overall Comparison

### 2) Short-term Interests Match

### 3) Aggressiveness of IRS

### 4) Effectiveness of the Personalized Mask Weight

### 5) Stepwise evolution of User Interests

### 6) Hyperparameter Tuning and Ablation Study

### 7) Case Study

# V. Conclusion
